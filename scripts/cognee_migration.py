#!/usr/bin/env python3
"""
Cognee Knowledge Migration Script
ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®å…¨ãƒŠãƒ¬ãƒƒã‚¸ã‚’Cogneeã«ç§»è¡Œã™ã‚‹
"""
import os
import time
import json
from pathlib import Path
from typing import List, Dict, Any
import asyncio
import logging
from dotenv import load_dotenv
import cognee

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class CogneeMigration:
    """Cogneeç§»è¡Œå‡¦ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, base_path: str = "/home/devuser/workspace"):
        self.base_path = Path(base_path)
        self.migration_log = []
        self.error_log = []
        
        # .env ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿
        env_path = self.base_path / "dev-tools/external-repos/cognee/.env"
        if env_path.exists():
            load_dotenv(env_path)
            logger.info(f"Environment variables loaded from: {env_path}")
        else:
            logger.warning(f"Environment file not found: {env_path}")
        
    def get_migration_files(self) -> Dict[str, List[str]]:
        """ç§»è¡Œå¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«å–å¾— - S+Aç´šå¯¾å¿œç‰ˆ"""
        files = {
            "s_grade_files": [
                # Sç´šãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆå…¨ã¦ç™»éŒ²æ¸ˆã¿ï¼‰
                # "memory-bank/00-core/user_authorization_mandatory.md",     # âœ… ç™»éŒ²æ¸ˆã¿
                # "memory-bank/00-core/testing_mandatory.md",               # âœ… ç™»éŒ²æ¸ˆã¿  
                # "memory-bank/00-core/code_quality_anti_hacking.md",       # âœ… ç™»éŒ²æ¸ˆã¿
                # "memory-bank/01-cognee/mandatory_utilization_rules.md",   # âœ… ç™»éŒ²æ¸ˆã¿
                # "memory-bank/09-meta/progress_recording_mandatory_rules.md"  # âœ… ç™»éŒ²æ¸ˆã¿
            ],
            "a_grade_files": [
                # Aç´šãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆæ®‹ã‚Š5ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰ - accuracy_verification_rules.md ã¨ critical_review_framework.md ã¯å®Ÿè¡Œä¸­ã®ãŸã‚é™¤å¤–
                "memory-bank/02-organization/delegation_decision_framework.md",
                "memory-bank/02-organization/task_tool_delegation_integration.md",
                "memory-bank/04-quality/test_strategy.md",
                "memory-bank/04-quality/tdd_process_failures_lessons.md",
                "memory-bank/01-cognee/migration_procedure.md"
            ],
        }
        
        # S+Aç´šã®ã¿ã®ç§»è¡Œãªã®ã§ã€ä»–ã®ã‚«ãƒ†ã‚´ãƒªã¯é™¤å¤–
        
        return files
    
    def validate_file_exists(self, file_path: str) -> bool:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª"""
        full_path = self.base_path / file_path
        return full_path.exists()
    
    async def migrate_file(self, file_path: str, category: str) -> Dict[str, Any]:
        """å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã®ç§»è¡Œï¼ˆCognee Python APIä½¿ç”¨ï¼‰"""
        result = {
            "file": file_path,
            "category": category,
            "status": "pending",
            "error": None,
            "timestamp": time.time()
        }
        
        try:
            if not self.validate_file_exists(file_path):
                raise FileNotFoundError(f"File not found: {file_path}")
            
            # Cognee Python APIã‚’ä½¿ç”¨
            logger.info(f"Migrating {category}: {file_path}")
            full_path = self.base_path / file_path
            
            # ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’èª­ã¿è¾¼ã¿
            with open(full_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Cogneeã«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’è¿½åŠ 
            logger.info(f"Adding document to Cognee: {file_path}")
            await cognee.add(content, dataset_name="main_dataset")
            
            # cognifyã¯ãƒãƒƒãƒã”ã¨ã«1å›å®Ÿè¡Œã™ã‚‹ã®ã§ã€ã“ã“ã§ã¯å®Ÿè¡Œã—ãªã„
            result["status"] = "added"
            logger.info(f"Document added: {file_path}")
            
            self.migration_log.append(result)
            
        except Exception as e:
            result["status"] = "failed"
            result["error"] = str(e)
            self.error_log.append(result)
            logger.error(f"Failed to migrate {file_path}: {e}")
        
        return result
    
    
    async def migrate_category(self, category: str, files: List[str], 
                             batch_size: int = 3) -> Dict[str, Any]:
        """ã‚«ãƒ†ã‚´ãƒªå˜ä½ã§ã®ç§»è¡Œï¼ˆä¸¦åˆ—å®Ÿè¡Œãƒ†ã‚¹ãƒˆï¼‰"""
        logger.info(f"\n=== Migrating {category} ({len(files)} files) ===")
        
        results = {
            "category": category,
            "total": len(files),
            "success": 0,
            "failed": 0,
            "files": []
        }
        
        # ä¸¦åˆ—å®Ÿè¡Œãƒ†ã‚¹ãƒˆï¼ˆãƒãƒƒãƒå‡¦ç†ï¼‰
        for i in range(0, len(files), batch_size):
            batch = files[i:i + batch_size]
            logger.info(f"Processing batch {i//batch_size + 1} ({len(batch)} files)")
            
            # ãƒãƒƒãƒå†…ä¸¦åˆ—å®Ÿè¡Œ
            batch_results = await asyncio.gather(
                *[self.migrate_file(f, category) for f in batch],
                return_exceptions=True
            )
            
            for idx, result in enumerate(batch_results):
                if isinstance(result, dict):
                    results["files"].append(result)
                    if result["status"] in ["added", "completed"]:
                        results["success"] += 1
                        logger.info(f"âœ… Completed: {batch[idx]}")
                    else:
                        results["failed"] += 1
                        logger.error(f"âŒ Failed: {batch[idx]} - {result['error']}")
                else:
                    results["failed"] += 1
                    logger.error(f"âŒ Exception in batch processing: {result}")
            
            # ãƒãƒƒãƒå®Œäº†å¾Œã«cognifyã‚’å®Ÿè¡Œ
            logger.info(f"Running cognify for batch {i//batch_size + 1}...")
            try:
                await cognee.cognify()
                logger.info(f"Cognify completed for batch {i//batch_size + 1}")
                
                # æˆåŠŸã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’æ›´æ–°
                for idx, file_result in enumerate(results["files"][-len(batch):]):
                    if file_result["status"] == "added":
                        file_result["status"] = "completed"
            except Exception as e:
                logger.error(f"Cognify failed for batch: {e}")
                # å¤±æ•—ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’æ›´æ–°
                for idx, file_result in enumerate(results["files"][-len(batch):]):
                    if file_result["status"] == "added":
                        file_result["status"] = "failed"
                        file_result["error"] = f"Cognify batch failed: {str(e)}"
            
            # ãƒãƒƒãƒé–“å¾…æ©Ÿï¼ˆãƒ¡ãƒ¢ãƒªè² è·è»½æ¸›ï¼‰
            if i + batch_size < len(files):
                logger.info("Waiting 60 seconds before next batch...")
                await asyncio.sleep(60)
        
        return results
    
    async def run_migration(self) -> Dict[str, Any]:
        """S+Aç´šç§»è¡Œå‡¦ç†ã®ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œï¼ˆéåŒæœŸç‰ˆï¼‰"""
        start_time = time.time()
        
        logger.info("Starting S+A Grade Cognee migration...")
        
        # Cogneeã®è¨­å®šï¼ˆç’°å¢ƒå¤‰æ•°ã‹ã‚‰èª­ã¿è¾¼ã¿ï¼‰
        cognee.config.llm_api_key = os.getenv("LLM_API_KEY")
        cognee.config.llm_model = os.getenv("LLM_MODEL", "openai/gpt-4o-mini")
        cognee.config.llm_provider = os.getenv("LLM_PROVIDER", "openai")
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­å®š
        cognee.config.db_provider = os.getenv("DB_PROVIDER", "sqlite")
        cognee.config.graph_database_provider = os.getenv("GRAPH_DATABASE_PROVIDER", "networkx")
        cognee.config.vector_db_provider = os.getenv("VECTOR_DB_PROVIDER", "lancedb")
        
        logger.info("Cognee configured with environment settings")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åé›†
        files_by_category = self.get_migration_files()
        
        # çµ±è¨ˆæƒ…å ±
        total_files = sum(len(files) for files in files_by_category.values())
        logger.info(f"Total S+A grade files to migrate: {total_files}")
        
        migration_results = {
            "total_files": total_files,
            "categories": {},
            "start_time": start_time,
            "phases": []
        }
        
        # Phase 2: Sç´šãƒ•ã‚¡ã‚¤ãƒ«ç§»è¡Œ
        logger.info("\n=== Phase 2: S-Grade Files ===")
        s_results = await self.migrate_category(
            "s_grade_files", 
            files_by_category["s_grade_files"],
            batch_size=1  # Sç´šã¯æ…é‡ã«1ãƒ•ã‚¡ã‚¤ãƒ«ãšã¤ï¼ˆç¾åœ¨ç©ºãªã®ã§ã‚¹ã‚­ãƒƒãƒ—ï¼‰
        )
        migration_results["categories"]["s_grade_files"] = s_results
        migration_results["phases"].append("s_grade_files")
        
        # Phase 3: Aç´šãƒ•ã‚¡ã‚¤ãƒ«ç§»è¡Œ  
        logger.info("\n=== Phase 3: A-Grade Files ===")
        a_results = await self.migrate_category(
            "a_grade_files",
            files_by_category["a_grade_files"],
            batch_size=2  # Aç´šã¯2ãƒ•ã‚¡ã‚¤ãƒ«ãšã¤ï¼ˆãƒ¡ãƒ¢ãƒªè² è·è€ƒæ…®ï¼‰
        )
        migration_results["categories"]["a_grade_files"] = a_results
        migration_results["phases"].append("a_grade_files")
        
        # ç§»è¡Œå®Œäº†
        end_time = time.time()
        migration_results["end_time"] = end_time
        migration_results["duration"] = end_time - start_time
        migration_results["success_count"] = sum(
            cat["success"] for cat in migration_results["categories"].values()
        )
        migration_results["error_count"] = len(self.error_log)
        
        # çµæœä¿å­˜
        self.save_migration_report(migration_results)
        
        return migration_results
    
    def save_migration_report(self, results: Dict[str, Any]):
        """ç§»è¡Œãƒ¬ãƒãƒ¼ãƒˆã®ä¿å­˜"""
        report_path = self.base_path / "output" / "reports" / "cognee_migration_report.json"
        report_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        logger.info(f"Migration report saved to: {report_path}")
        
        # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã®ä¿å­˜
        if self.error_log:
            error_path = self.base_path / "output" / "reports" / "cognee_migration_errors.json"
            with open(error_path, 'w', encoding='utf-8') as f:
                json.dump(self.error_log, f, indent=2, ensure_ascii=False)
            logger.warning(f"Error log saved to: {error_path}")


async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•° - S+Aç´šå®Ÿè¡Œï¼ˆéåŒæœŸç‰ˆï¼‰"""
    migration = CogneeMigration()
    
    logger.info("Running S+A Grade Migration with Cognee Python API")
    logger.info("Using batch processing with cognify after each batch...")
    
    results = await migration.run_migration()
    
    # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
    print("\n" + "="*60)
    print("S+A GRADE MIGRATION SUMMARY")
    print("="*60)
    print(f"Total files: {results['total_files']}")
    print(f"Success: {results['success_count']}")
    print(f"Failed: {results['error_count']}")
    print(f"Duration: {results['duration']:.2f} seconds")
    print("\nBy Category:")
    for category, cat_results in results['categories'].items():
        print(f"  {category}: {cat_results['success']}/{cat_results['total']}")
    
    # åˆæ ¼åŸºæº–ãƒã‚§ãƒƒã‚¯
    success_rate = results['success_count'] / results['total_files'] * 100
    print(f"\nğŸ“Š Success Rate: {success_rate:.1f}%")
    
    if success_rate >= 100:
        print("âœ… PASSED: All files migrated successfully!")
    elif success_rate >= 80:
        print("âš ï¸ PARTIAL: Most files migrated, check failed files")
    else:
        print("âŒ FAILED: Migration did not meet success criteria")


if __name__ == "__main__":
    asyncio.run(main())