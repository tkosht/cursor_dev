#!/usr/bin/env python3
"""
æ‰¹åˆ¤çš„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ã‚¼ãƒ­ãƒ™ãƒ¼ã‚¹ã§ã®å®¢è¦³çš„ãƒ»æ‰¹åˆ¤çš„ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’è‡ªå‹•åŒ–

ä½¿ç”¨æ–¹æ³•:
  python scripts/critical_documentation_review.py --target README.md
  python scripts/critical_documentation_review.py --all
"""

import argparse
import re
import subprocess
import sys
import tempfile
from pathlib import Path
from typing import List, Dict, Set, Tuple
from dataclasses import dataclass
from datetime import datetime

@dataclass
class ReviewFinding:
    """ãƒ¬ãƒ“ãƒ¥ãƒ¼ç™ºè¦‹äº‹é …"""
    severity: str  # CRITICAL, HIGH, MEDIUM, LOW
    category: str  # ACCURACY, CLARITY, COMPLETENESS, CONSISTENCY
    file_path: str
    line_number: int
    description: str
    suggestion: str
    evidence: str = ""

class CriticalDocumentationReviewer:
    """æ‰¹åˆ¤çš„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¢"""
    
    def __init__(self):
        self.findings: List[ReviewFinding] = []
        self.project_root = Path.cwd()
        self.verified_commands: Set[str] = set()
        self.verified_files: Set[str] = set()
    
    def review_document(self, doc_path: Path) -> None:
        """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®æ‰¹åˆ¤çš„ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Ÿè¡Œ"""
        print(f"ğŸ” æ‰¹åˆ¤çš„ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¸­: {doc_path.relative_to(self.project_root)}")
        
        with open(doc_path, 'r', encoding='utf-8') as f:
            content = f.read()
            lines = content.split('\n')
        
        # å„ç¨®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å®Ÿè¡Œ
        self._review_command_accuracy(doc_path, content, lines)
        self._review_claims_verification(doc_path, content, lines)
        self._review_clarity_consistency(doc_path, content, lines)
        self._review_completeness(doc_path, content, lines)
        self._review_maintainability(doc_path, content, lines)
    
    def _review_command_accuracy(self, doc_path: Path, content: str, lines: List[str]) -> None:
        """ã‚³ãƒãƒ³ãƒ‰æ­£ç¢ºæ€§ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼"""
        
        # ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯å†…ã®ã‚³ãƒãƒ³ãƒ‰ã‚’æŠ½å‡º
        code_blocks = re.findall(r'```(?:bash|shell)?\n(.*?)\n```', content, re.DOTALL)
        
        for block_idx, block in enumerate(code_blocks):
            block_lines = block.split('\n')
            for line_idx, line in enumerate(block_lines):
                line = line.strip()
                if not line or line.startswith('#'):
                    continue
                
                # å„ç¨®ã‚³ãƒãƒ³ãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒã‚§ãƒƒã‚¯
                self._check_make_commands(doc_path, line, block_idx)
                self._check_python_commands(doc_path, line, block_idx)
                self._check_file_paths(doc_path, line, block_idx)
    
    def _check_make_commands(self, doc_path: Path, command: str, block_idx: int) -> None:
        """makeã‚³ãƒãƒ³ãƒ‰ã®æ¤œè¨¼"""
        make_match = re.search(r'make\s+([a-zA-Z0-9_-]+)', command)
        if not make_match:
            return
        
        target = make_match.group(1)
        makefile_path = self.project_root / 'Makefile'
        
        if not makefile_path.exists():
            self.findings.append(ReviewFinding(
                severity="HIGH",
                category="ACCURACY",
                file_path=str(doc_path.relative_to(self.project_root)),
                line_number=block_idx + 1,
                description=f"MakefileãŒå­˜åœ¨ã—ãªã„ã®ã« 'make {target}' ã‚’ä½¿ç”¨",
                suggestion="Makefileã‚’ä½œæˆã™ã‚‹ã‹ã€è©²å½“ã‚³ãƒãƒ³ãƒ‰ã‚’å‰Šé™¤ã—ã¦ãã ã•ã„",
                evidence=f"Command: {command}"
            ))
            return
        
        # Makefileã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆä¸€è¦§ã‚’å–å¾—
        if target not in self.verified_commands:
            try:
                result = subprocess.run(
                    ['make', '-n', target], 
                    cwd=self.project_root,
                    capture_output=True,
                    text=True,
                    timeout=10
                )
                if result.returncode != 0:
                    self.findings.append(ReviewFinding(
                        severity="CRITICAL",
                        category="ACCURACY", 
                        file_path=str(doc_path.relative_to(self.project_root)),
                        line_number=block_idx + 1,
                        description=f"å­˜åœ¨ã—ãªã„Makeã‚¿ãƒ¼ã‚²ãƒƒãƒˆ 'make {target}'",
                        suggestion=f"Makefileã«ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ '{target}' ã‚’è¿½åŠ ã™ã‚‹ã‹ã€ã‚³ãƒãƒ³ãƒ‰ã‚’ä¿®æ­£ã—ã¦ãã ã•ã„",
                        evidence=f"Command: {command}\nError: {result.stderr.strip()}"
                    ))
                else:
                    self.verified_commands.add(target)
            except subprocess.TimeoutExpired:
                self.findings.append(ReviewFinding(
                    severity="MEDIUM",
                    category="ACCURACY",
                    file_path=str(doc_path.relative_to(self.project_root)),
                    line_number=block_idx + 1,
                    description=f"Makeã‚¿ãƒ¼ã‚²ãƒƒãƒˆ '{target}' ã®æ¤œè¨¼ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ",
                    suggestion="ã‚³ãƒãƒ³ãƒ‰ã®å®Ÿè¡Œæ™‚é–“ã‚’ç¢ºèªã—ã¦ãã ã•ã„",
                    evidence=f"Command: {command}"
                ))
    
    def _check_python_commands(self, doc_path: Path, command: str, block_idx: int) -> None:
        """Pythonã‚³ãƒãƒ³ãƒ‰ã®æ¤œè¨¼"""
        python_match = re.search(r'python\s+(scripts/[^\s]+)', command)
        if not python_match:
            return
        
        script_path = python_match.group(1)
        full_script_path = self.project_root / script_path
        
        if not full_script_path.exists():
            self.findings.append(ReviewFinding(
                severity="CRITICAL",
                category="ACCURACY",
                file_path=str(doc_path.relative_to(self.project_root)),
                line_number=block_idx + 1,
                description=f"å­˜åœ¨ã—ãªã„ã‚¹ã‚¯ãƒªãƒ—ãƒˆ '{script_path}' ã‚’å‚ç…§",
                suggestion=f"ã‚¹ã‚¯ãƒªãƒ—ãƒˆ '{script_path}' ã‚’ä½œæˆã™ã‚‹ã‹ã€ãƒ‘ã‚¹ã‚’ä¿®æ­£ã—ã¦ãã ã•ã„",
                evidence=f"Command: {command}"
            ))
        elif script_path not in self.verified_files:
            # ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®å®Ÿè¡Œå¯èƒ½æ€§ã‚’ç¢ºèª
            try:
                result = subprocess.run(
                    ['python', script_path, '--help'],
                    cwd=self.project_root,
                    capture_output=True,
                    text=True,
                    timeout=60
                )
                if result.returncode not in [0, 1, 2]:  # ä¸€èˆ¬çš„ãªæ­£å¸¸çµ‚äº†ã‚³ãƒ¼ãƒ‰
                    self.findings.append(ReviewFinding(
                        severity="HIGH", 
                        category="ACCURACY",
                        file_path=str(doc_path.relative_to(self.project_root)),
                        line_number=block_idx + 1,
                        description=f"ã‚¹ã‚¯ãƒªãƒ—ãƒˆ '{script_path}' ã®å®Ÿè¡Œã«å¤±æ•—",
                        suggestion="ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®æ§‹æ–‡ã‚¨ãƒ©ãƒ¼ã¾ãŸã¯ä¾å­˜é–¢ä¿‚ã‚’ç¢ºèªã—ã¦ãã ã•ã„",
                        evidence=f"Command: {command}\nError: {result.stderr.strip()}"
                    ))
                else:
                    self.verified_files.add(script_path)
            except subprocess.TimeoutExpired:
                self.findings.append(ReviewFinding(
                    severity="MEDIUM",
                    category="ACCURACY",
                    file_path=str(doc_path.relative_to(self.project_root)),
                    line_number=block_idx + 1,
                    description=f"ã‚¹ã‚¯ãƒªãƒ—ãƒˆ '{script_path}' ã®æ¤œè¨¼ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ",
                    suggestion="ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®å®Ÿè¡Œæ™‚é–“ã‚’ç¢ºèªã—ã¦ãã ã•ã„",
                    evidence=f"Command: {command}"
                ))
    
    def _check_file_paths(self, doc_path: Path, command: str, block_idx: int) -> None:
        """ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®æ¤œè¨¼"""
        # Markdownãƒªãƒ³ã‚¯ã¯é™¤å¤–ï¼ˆã“ã®é–¢æ•°ã¯ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯å†…ã®ã‚³ãƒãƒ³ãƒ‰å°‚ç”¨ï¼‰
        if '](' in command or command.strip().startswith('- **['):
            return
            
        # ä¸€èˆ¬çš„ãªãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œç´¢ï¼ˆã‚ˆã‚Šå³å¯†ãªãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
        file_patterns = [
            r'(app/[^\s\]\)]+\.py)',
            r'(tests/[^\s\]\)]+\.py)', 
            r'(docs/[^\s\]\)]+\.md)',
            r'([^\s\]\)]+\.yml)',
            r'([^\s\]\)]+\.yaml)',
            r'([^\s\]\)]+\.json)',
            r'([^\s\]\)]+\.toml)'
        ]
        
        for pattern in file_patterns:
            matches = re.findall(pattern, command)
            for file_path in matches:
                # Markdownãƒªãƒ³ã‚¯æ§‹æ–‡ã®ä¸€éƒ¨ã‚’é™¤å¤–
                if '](' in file_path or file_path.endswith(']'):
                    continue
                    
                full_path = self.project_root / file_path
                if not full_path.exists():
                    self.findings.append(ReviewFinding(
                        severity="HIGH",
                        category="ACCURACY", 
                        file_path=str(doc_path.relative_to(self.project_root)),
                        line_number=block_idx + 1,
                        description=f"å­˜åœ¨ã—ãªã„ãƒ•ã‚¡ã‚¤ãƒ« '{file_path}' ã‚’å‚ç…§",
                        suggestion=f"ãƒ•ã‚¡ã‚¤ãƒ« '{file_path}' ã‚’ä½œæˆã™ã‚‹ã‹ã€ãƒ‘ã‚¹ã‚’ä¿®æ­£ã—ã¦ãã ã•ã„",
                        evidence=f"Command: {command}"
                    ))
    
    def _review_claims_verification(self, doc_path: Path, content: str, lines: List[str]) -> None:
        """ä¸»å¼µãƒ»æ•°å€¤ã®æ¤œè¨¼å¯èƒ½æ€§ãƒ¬ãƒ“ãƒ¥ãƒ¼"""
        
        # æ¤œè¨¼å›°é›£ãªæ•°å€¤çš„ä¸»å¼µã‚’æ¤œç´¢
        unverifiable_patterns = [
            (r'(\d+)æ—¥é–“.*é–‹ç™º', "é–‹ç™ºæœŸé–“ã®ä¸»å¼µã«æ ¹æ‹ ãŒå¿…è¦"),
            (r'(\d+(?:\.\d+)?)ms.*ãƒ¬ã‚¹ãƒãƒ³ã‚¹', "ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ã®æ¸¬å®šæ–¹æ³•ãŒå¿…è¦"),
            (r'(\d+(?:\.\d+)?)å€.*å‘ä¸Š', "æ€§èƒ½å‘ä¸Šã®æ¸¬å®šåŸºæº–ãŒå¿…è¦"),
            (r'æ¥­ç•Œå¹³å‡.*(\d+)', "æ¥­ç•Œå¹³å‡ã®å‡ºå…¸ãŒå¿…è¦"),
        ]
        
        for line_idx, line in enumerate(lines):
            for pattern, message in unverifiable_patterns:
                if re.search(pattern, line):
                    # åŒä¸€è¡Œã¾ãŸã¯è¿‘å‚è¡Œã«æ ¹æ‹ ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                    context_lines = lines[max(0, line_idx-2):min(len(lines), line_idx+3)]
                    context = '\n'.join(context_lines)
                    
                    # æ ¹æ‹ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®å­˜åœ¨ç¢ºèª
                    evidence_keywords = ['æ¸¬å®š', 'å®Ÿæ¸¬', 'æ¤œè¨¼', 'ãƒ†ã‚¹ãƒˆ', 'ç¢ºèª', 'time', 'pytest', 'benchmark']
                    has_evidence = any(keyword in context for keyword in evidence_keywords)
                    
                    if not has_evidence:
                        self.findings.append(ReviewFinding(
                            severity="MEDIUM",
                            category="ACCURACY",
                            file_path=str(doc_path.relative_to(self.project_root)),
                            line_number=line_idx + 1,
                            description=f"æ¤œè¨¼å›°é›£ãªæ•°å€¤çš„ä¸»å¼µ: {message}",
                            suggestion="æ¸¬å®šæ–¹æ³•ã€æ¸¬å®šæ—¥æ™‚ã€æ¸¬å®šç’°å¢ƒã‚’æ˜è¨˜ã—ã¦ãã ã•ã„",
                            evidence=f"Line: {line.strip()}"
                        ))
    
    def _review_clarity_consistency(self, doc_path: Path, content: str, lines: List[str]) -> None:
        """æ˜ç¢ºæ€§ãƒ»ä¸€è²«æ€§ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼"""
        
        # æ›–æ˜§ãªè¡¨ç¾ã‚’æ¤œç´¢
        vague_patterns = [
            (r'é«˜æ€§èƒ½', "å…·ä½“çš„ãªæ•°å€¤ãƒ»æŒ‡æ¨™ã§è¡¨ç¾ã—ã¦ãã ã•ã„"),
            (r'é«˜å“è³ª', "å“è³ªã®æŒ‡æ¨™ï¼ˆãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸ã€ãƒã‚°æ•°ç­‰ï¼‰ã‚’æ˜è¨˜ã—ã¦ãã ã•ã„"),
            (r'ç°¡å˜(?:ã«|ãª)', "å…·ä½“çš„ãªæ‰‹é †æ•°ã‚„æ™‚é–“ã‚’æ˜è¨˜ã—ã¦ãã ã•ã„"),
            (r'ã™ãã«', "å…·ä½“çš„ãªæ™‚é–“ã‚’æ˜è¨˜ã—ã¦ãã ã•ã„"),
            (r'ãŸãã•ã‚“', "å…·ä½“çš„ãªæ•°é‡ã‚’æ˜è¨˜ã—ã¦ãã ã•ã„"),
        ]
        
        for line_idx, line in enumerate(lines):
            for pattern, suggestion in vague_patterns:
                if re.search(pattern, line):
                    self.findings.append(ReviewFinding(
                        severity="LOW",
                        category="CLARITY",
                        file_path=str(doc_path.relative_to(self.project_root)),
                        line_number=line_idx + 1,
                        description=f"æ›–æ˜§ãªè¡¨ç¾: {pattern}",
                        suggestion=suggestion,
                        evidence=f"Line: {line.strip()}"
                    ))
    
    def _review_completeness(self, doc_path: Path, content: str, lines: List[str]) -> None:
        """å®Œå…¨æ€§ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼"""
        
        # README.mdã®å ´åˆã€å¿…é ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ãƒã‚§ãƒƒã‚¯
        if doc_path.name == 'README.md':
            required_sections = [
                ('## ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«', 'ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ‰‹é †'),
                ('## ä½¿ç”¨æ–¹æ³•', 'åŸºæœ¬çš„ãªä½¿ç”¨æ–¹æ³•'),  
                ('## é–‹ç™º', 'é–‹ç™ºç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—'),
                ('## ãƒ†ã‚¹ãƒˆ', 'ãƒ†ã‚¹ãƒˆå®Ÿè¡Œæ–¹æ³•'),
                ('## ãƒ©ã‚¤ã‚»ãƒ³ã‚¹', 'ãƒ©ã‚¤ã‚»ãƒ³ã‚¹æƒ…å ±')
            ]
            
            for section_pattern, description in required_sections:
                if not re.search(section_pattern, content, re.IGNORECASE):
                    self.findings.append(ReviewFinding(
                        severity="MEDIUM",
                        category="COMPLETENESS",
                        file_path=str(doc_path.relative_to(self.project_root)),
                        line_number=1,
                        description=f"å¿…é ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ä¸è¶³: {description}",
                        suggestion=f"ã‚»ã‚¯ã‚·ãƒ§ãƒ³ '{section_pattern}' ã‚’è¿½åŠ ã—ã¦ãã ã•ã„",
                        evidence=""
                    ))
    
    def _review_maintainability(self, doc_path: Path, content: str, lines: List[str]) -> None:
        """ä¿å®ˆæ€§ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼"""
        
        # æ—¥ä»˜ã®è¨˜è¼‰ãŒã‚ã‚‹ã‹ï¼ˆå¤ã„æƒ…å ±ã®æ¤œå‡ºï¼‰
        date_patterns = [
            r'æœ€çµ‚æ›´æ–°.*(\d{4})',
            r'æ¤œè¨¼æ—¥.*(\d{4}-\d{2}-\d{2})',
            r'æ¸¬å®šæ—¥.*(\d{4}-\d{2}-\d{2})'
        ]
        
        has_date_info = False
        for line in lines:
            for pattern in date_patterns:
                if re.search(pattern, line):
                    has_date_info = True
                    break
            if has_date_info:
                break
        
        if not has_date_info and doc_path.name == 'README.md':
            self.findings.append(ReviewFinding(
                severity="LOW",
                category="MAINTAINABILITY",
                file_path=str(doc_path.relative_to(self.project_root)),
                line_number=1,
                description="æœ€çµ‚æ›´æ–°æ—¥ã®è¨˜è¼‰ãŒã‚ã‚Šã¾ã›ã‚“",
                suggestion="ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®æœ€çµ‚æ›´æ–°æ—¥ã‚’è¨˜è¼‰ã—ã¦ãã ã•ã„",
                evidence=""
            ))
    
    def generate_report(self) -> int:
        """ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""
        print("\n" + "=" * 80)
        print("ğŸ“Š Critical Documentation Review Report")
        print("=" * 80)
        print(f"ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Ÿè¡Œæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print()
        
        if not self.findings:
            print("âœ… Excellent! No critical issues found.")
            print("ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯æ‰¹åˆ¤çš„ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ãƒ‘ã‚¹ã—ã¾ã—ãŸã€‚")
            print("=" * 80)
            return 0
        
        # é‡è¦åº¦åˆ¥ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        by_severity = {}
        for finding in self.findings:
            if finding.severity not in by_severity:
                by_severity[finding.severity] = []
            by_severity[finding.severity].append(finding)
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        by_category = {}
        for finding in self.findings:
            if finding.category not in by_category:
                by_category[finding.category] = []
            by_category[finding.category].append(finding)
        
        # é‡è¦åº¦é †ã§è¡¨ç¤º
        severity_order = ['CRITICAL', 'HIGH', 'MEDIUM', 'LOW']
        
        for severity in severity_order:
            if severity in by_severity:
                findings = by_severity[severity]
                icon = {'CRITICAL': 'ğŸš¨', 'HIGH': 'âŒ', 'MEDIUM': 'âš ï¸', 'LOW': 'ğŸ’¡'}[severity]
                print(f"\n{icon} {severity} Issues ({len(findings)}ä»¶):")
                print("-" * 80)
                
                for i, finding in enumerate(findings, 1):
                    print(f"{i:3d}. [{finding.category}] {finding.file_path}:{finding.line_number}")
                    print(f"     å•é¡Œ: {finding.description}")
                    print(f"     ææ¡ˆ: {finding.suggestion}")
                    if finding.evidence:
                        print(f"     æ ¹æ‹ : {finding.evidence}")
                    print()
        
        # ã‚µãƒãƒªãƒ¼çµ±è¨ˆ
        print("=" * 80)
        print("ğŸ“ˆ Summary Statistics:")
        print("-" * 80)
        for severity in severity_order:
            count = len(by_severity.get(severity, []))
            if count > 0:
                print(f"{severity}: {count}ä»¶")
        
        print("\nã‚«ãƒ†ã‚´ãƒªåˆ¥:")
        for category, findings in by_category.items():
            print(f"{category}: {len(findings)}ä»¶")
        
        print("\n" + "=" * 80)
        
        # é‡è¦åº¦ã«å¿œã˜ã¦çµ‚äº†ã‚³ãƒ¼ãƒ‰ã‚’æ±ºå®š
        if 'CRITICAL' in by_severity:
            return 2
        elif 'HIGH' in by_severity:
            return 1
        else:
            return 0
    
    def run(self, target_files: List[Path]) -> int:
        """æ‰¹åˆ¤çš„ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®å®Ÿè¡Œ"""
        print("ğŸ”¬ Critical Documentation Review Starting...")
        print("=" * 80)
        print("ğŸ“‹ ãƒ¬ãƒ“ãƒ¥ãƒ¼åŸå‰‡:")
        print("âœ… äº‹å®Ÿãƒ™ãƒ¼ã‚¹ã®è¨˜è¼‰ã®ã¿è¨±å¯")
        print("âœ… å…¨ã¦ã®ä¸»å¼µã«æ¤œè¨¼å¯èƒ½ãªæ ¹æ‹ ãŒå¿…è¦")
        print("âœ… æ¨æ¸¬ãƒ»æ†¶æ¸¬ã¯æ˜ç¢ºã«åŒºåˆ¥ã—ã¦è¨˜è¼‰")
        print("âœ… ã‚¼ãƒ­ãƒ™ãƒ¼ã‚¹ã§ã®å®¢è¦³çš„è©•ä¾¡")
        print("=" * 80)
        
        for doc_path in target_files:
            if doc_path.exists() and doc_path.suffix == '.md':
                self.review_document(doc_path)
        
        return self.generate_report()

def main():
    """ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ"""
    parser = argparse.ArgumentParser(description='æ‰¹åˆ¤çš„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ¬ãƒ“ãƒ¥ãƒ¼')
    parser.add_argument('--target', type=str, help='ãƒ¬ãƒ“ãƒ¥ãƒ¼å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«')
    parser.add_argument('--all', action='store_true', help='å…¨Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼')
    
    args = parser.parse_args()
    
    reviewer = CriticalDocumentationReviewer()
    
    if args.all:
        target_files = list(reviewer.project_root.glob('**/*.md'))
        # é™¤å¤–ãƒ‘ã‚¹
        target_files = [
            f for f in target_files 
            if not any(exclude in str(f) for exclude in ['.venv', 'node_modules', 'htmlcov', '.git'])
        ]
    elif args.target:
        target_files = [reviewer.project_root / args.target]
    else:
        target_files = [reviewer.project_root / 'README.md']
    
    return reviewer.run(target_files)

if __name__ == "__main__":
    sys.exit(main())