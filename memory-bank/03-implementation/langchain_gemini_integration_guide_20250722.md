# LangChain + Google Gemini API çµ±åˆå®Ÿè£…ã‚¬ã‚¤ãƒ‰

## ğŸ“… ä½œæˆæ—¥: 2025-07-22
## ğŸ·ï¸ ã‚¿ã‚°: langchain, gemini, google-ai, llm, integration, real-api-calls

## ğŸ¯ ç›®çš„
å®Ÿéš›ã®LLM APIå‘¼ã³å‡ºã—ã‚’ä½¿ç”¨ã—ãŸLangChain + Google Geminiçµ±åˆã®æ­£ã—ã„å®Ÿè£…æ–¹æ³•ã‚’è¨˜éŒ²

## ğŸ“š å‚ç…§æƒ…å ±
- WebSearchçµæœ: LangChainå…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
- å†…éƒ¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ: @docs/langgraph-agent-communication-design.md
- å†…éƒ¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ: @docs/langgraph-implementation-guide.md

## ğŸ”§ å®Ÿè£…æ–¹æ³•

### 1. å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
```bash
pip install langchain langchain-google-genai google-generativeai python-dotenv
```

### 2. ç’°å¢ƒå¤‰æ•°ã®è¨­å®š
```python
# .env ãƒ•ã‚¡ã‚¤ãƒ«
GOOGLE_API_KEY=your-api-key-here
```

### 3. åŸºæœ¬çš„ãªLLMå‘¼ã³å‡ºã—å®Ÿè£…
```python
import os
from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()

# LLMã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®ä½œæˆ
def create_llm():
    """Google Gemini LLMã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ"""
    return ChatGoogleGenerativeAI(
        model="gemini-1.5-flash",
        google_api_key=os.getenv("GOOGLE_API_KEY"),
        temperature=0.7,
        max_tokens=2048
    )

# åŒæœŸå‘¼ã³å‡ºã—
def simple_llm_call():
    llm = create_llm()
    response = llm.invoke("ã“ã‚“ã«ã¡ã¯ã€‚1+1ã¯ä½•ã§ã™ã‹ï¼Ÿ")
    print(f"Response: {response.content}")
    return response

# éåŒæœŸå‘¼ã³å‡ºã—
async def async_llm_call():
    llm = create_llm()
    response = await llm.ainvoke("ã“ã‚“ã«ã¡ã¯ã€‚1+1ã¯ä½•ã§ã™ã‹ï¼Ÿ")
    print(f"Response: {response.content}")
    return response
```

### 4. LangGraphã§ã®çµ±åˆ
```python
from langgraph.graph import StateGraph, MessagesState
from typing import TypedDict, Annotated
from langgraph.graph import add_messages

class State(TypedDict):
    messages: Annotated[list, add_messages]
    context: dict

async def llm_node(state: State) -> dict:
    """LangGraphãƒãƒ¼ãƒ‰å†…ã§ã®LLMå‘¼ã³å‡ºã—"""
    llm = create_llm()
    
    # æœ€æ–°ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å–å¾—
    last_message = state["messages"][-1] if state["messages"] else "Hello"
    
    # LLMå‘¼ã³å‡ºã—
    response = await llm.ainvoke(last_message)
    
    # çŠ¶æ…‹ã®æ›´æ–°
    return {
        "messages": [("assistant", response.content)],
        "context": {"llm_called": True}
    }
```

### 5. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
```python
import asyncio
from tenacity import retry, stop_after_attempt, wait_exponential

@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=4, max=10)
)
async def robust_llm_call(prompt: str):
    """å†è©¦è¡Œä»˜ãã®LLMå‘¼ã³å‡ºã—"""
    try:
        llm = create_llm()
        response = await llm.ainvoke(prompt)
        return response.content
    except Exception as e:
        print(f"LLMå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {e}")
        raise
```

## ğŸ§ª å‹•ä½œç¢ºèªæ¸ˆã¿ã‚³ãƒ¼ãƒ‰

### æœ€å°é™ã®å‹•ä½œç¢ºèªã‚¹ã‚¯ãƒªãƒ—ãƒˆ
```python
"""test_llm_connection.py"""
import asyncio
import os
from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI

load_dotenv()

async def test_connection():
    """æ¥ç¶šãƒ†ã‚¹ãƒˆ"""
    print("=== LLMæ¥ç¶šãƒ†ã‚¹ãƒˆ ===")
    
    # API ã‚­ãƒ¼ã®ç¢ºèª
    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        print("âŒ GOOGLE_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return False
    
    print(f"âœ… API Key: {api_key[:10]}...")
    
    try:
        # LLMä½œæˆ
        llm = ChatGoogleGenerativeAI(
            model="gemini-1.5-flash",
            google_api_key=api_key
        )
        
        # ãƒ†ã‚¹ãƒˆå‘¼ã³å‡ºã—
        response = await llm.ainvoke("Hello, this is a test. Reply with 'OK'.")
        print(f"âœ… Response: {response.content}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Error: {e}")
        return False

if __name__ == "__main__":
    success = asyncio.run(test_connection())
    exit(0 if success else 1)
```

## ğŸ’° ã‚³ã‚¹ãƒˆè¦‹ç©ã‚‚ã‚Š

| ãƒ¢ãƒ‡ãƒ« | å…¥åŠ› | å‡ºåŠ› | æ¨å®šã‚³ã‚¹ãƒˆ/1000å‘¼ã³å‡ºã— |
|--------|------|------|------------------------|
| gemini-1.5-flash | $0.075/1M tokens | $0.30/1M tokens | ~$2-5 |
| gemini-1.5-pro | $1.25/1M tokens | $5.00/1M tokens | ~$20-50 |

## âš ï¸ æ³¨æ„äº‹é …

1. **API ã‚­ãƒ¼ç®¡ç†**
   - çµ¶å¯¾ã«ã‚³ãƒ¼ãƒ‰ã«ç›´æ¥è¨˜è¼‰ã—ãªã„
   - .envãƒ•ã‚¡ã‚¤ãƒ«ã¯.gitignoreã«è¿½åŠ 
   - ç’°å¢ƒå¤‰æ•°çµŒç”±ã§ã®ã¿ã‚¢ã‚¯ã‚»ã‚¹

2. **ãƒ¬ãƒ¼ãƒˆåˆ¶é™**
   - gemini-1.5-flash: 60 RPM (requests per minute)
   - å†è©¦è¡Œãƒ­ã‚¸ãƒƒã‚¯ã‚’å®Ÿè£…

3. **ãƒ¢ãƒƒã‚¯ä½¿ç”¨ç¦æ­¢**
   - çµ±åˆãƒ†ã‚¹ãƒˆã§ã¯å®Ÿéš›ã®APIå‘¼ã³å‡ºã—ã‚’ä½¿ç”¨
   - å°è¦æ¨¡ãƒ†ã‚¹ãƒˆï¼ˆ3-5å‘¼ã³å‡ºã—ï¼‰ã§å‹•ä½œç¢ºèª

## ğŸ”— é–¢é€£ãƒªãƒ³ã‚¯
- [LangChain Google Generative AI Documentation](https://python.langchain.com/docs/integrations/chat/google_generative_ai/)
- [Google AI Studio](https://ai.google.dev/)
- [Gemini API Pricing](https://ai.google.dev/pricing)