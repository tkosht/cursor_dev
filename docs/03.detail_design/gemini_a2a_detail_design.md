# Gemini-2.5-Proçµ±åˆA2Aã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ - è©³ç´°è¨­è¨ˆæ›¸

## 1. ã‚¯ãƒ©ã‚¹è©³ç´°è¨­è¨ˆ

### 1.1 GeminiConfig ã‚¯ãƒ©ã‚¹

```python
# app/a2a_prototype/utils/gemini_config.py

import os
from dataclasses import dataclass
from typing import Optional, Dict, Any

@dataclass
class GeminiConfig:
    """Gemini API ã®è¨­å®šæƒ…å ±ã‚’ç®¡ç†ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹"""
    
    api_key: str
    model: str = "gemini-2.5-pro-preview-05-06"
    temperature: float = 0.7
    max_tokens: int = 1000
    safety_settings: Optional[Dict[str, Any]] = None
    
    def __post_init__(self) -> None:
        """è¨­å®šå€¤ã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³"""
        self._validate_api_key()
        self._validate_temperature()
        self._validate_max_tokens()
        self._validate_model()
    
    def _validate_api_key(self) -> None:
        """APIã‚­ãƒ¼ã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³"""
        if not self.api_key or not isinstance(self.api_key, str):
            raise ValueError("API key must be a non-empty string")
        if len(self.api_key) < 10:  # æœ€ä½é™ã®é•·ã•ãƒã‚§ãƒƒã‚¯
            raise ValueError("API key appears to be invalid (too short)")
    
    def _validate_temperature(self) -> None:
        """Temperatureãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³"""
        if not isinstance(self.temperature, (int, float)):
            raise ValueError("Temperature must be a number")
        if not 0.0 <= self.temperature <= 1.0:
            raise ValueError("Temperature must be between 0.0 and 1.0")
    
    def _validate_max_tokens(self) -> None:
        """Max tokensãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³"""
        if not isinstance(self.max_tokens, int):
            raise ValueError("Max tokens must be an integer")
        if not 1 <= self.max_tokens <= 8192:  # Geminiåˆ¶é™ã«åŸºã¥ã
            raise ValueError("Max tokens must be between 1 and 8192")
    
    def _validate_model(self) -> None:
        """ãƒ¢ãƒ‡ãƒ«åã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³"""
        if not self.model or not isinstance(self.model, str):
            raise ValueError("Model must be a non-empty string")
        valid_models = ["gemini-2.5-pro-preview-05-06", "gemini-1.5-pro", "gemini-1.0-pro"]
        if self.model not in valid_models:
            # è­¦å‘Šã¯å‡ºã™ãŒã€æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã®å¯èƒ½æ€§ã‚‚ã‚ã‚‹ã®ã§ã‚¨ãƒ©ãƒ¼ã«ã¯ã—ãªã„
            import logging
            logging.warning(f"Unknown model: {self.model}. Valid models: {valid_models}")
    
    @classmethod
    def from_env(cls) -> "GeminiConfig":
        """ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šã‚’èª­ã¿è¾¼ã¿"""
        api_key = os.getenv("GEMINI_API_KEY")
        if not api_key:
            raise ValueError("GEMINI_API_KEY environment variable is required")
        
        return cls(
            api_key=api_key,
            model=os.getenv("GEMINI_MODEL", "gemini-2.5-pro-preview-05-06"),
            temperature=float(os.getenv("GEMINI_TEMPERATURE", "0.7")),
            max_tokens=int(os.getenv("GEMINI_MAX_TOKENS", "1000"))
        )
    
    def to_generation_config(self) -> Dict[str, Any]:
        """Gemini GenerationConfigå½¢å¼ã«å¤‰æ›"""
        return {
            "temperature": self.temperature,
            "max_output_tokens": self.max_tokens,
        }
    
    def get_masked_api_key(self) -> str:
        """ãƒã‚¹ã‚­ãƒ³ã‚°ã•ã‚ŒãŸAPIã‚­ãƒ¼ã‚’å–å¾—ï¼ˆãƒ­ã‚°å‡ºåŠ›ç”¨ï¼‰"""
        if len(self.api_key) <= 8:
            return "*" * len(self.api_key)
        return f"{self.api_key[:8]}{'*' * (len(self.api_key) - 8)}"
```

### 1.2 GeminiClient ã‚¯ãƒ©ã‚¹

```python
# app/a2a_prototype/utils/gemini_client.py

import asyncio
import logging
from typing import Optional, Dict, Any

import google.generativeai as genai
from google.generativeai.types import GenerationConfig, HarmCategory, HarmBlockThreshold

from .gemini_config import GeminiConfig

logger = logging.getLogger(__name__)

class GeminiAPIError(Exception):
    """Gemini API é–¢é€£ã®ã‚¨ãƒ©ãƒ¼"""
    pass

class GeminiClient:
    """Gemini AI API ã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆWrapper"""
    
    def __init__(self, config: GeminiConfig) -> None:
        """
        Args:
            config: Gemini APIè¨­å®š
        """
        self.config = config
        self._model: Optional[genai.GenerativeModel] = None
        self._initialized = False
        self._setup_client()
    
    def _setup_client(self) -> None:
        """Geminiã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        try:
            # APIèªè¨¼è¨­å®š
            genai.configure(api_key=self.config.api_key)
            
            # Safety settings
            safety_settings = self._get_safety_settings()
            
            # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
            self._model = genai.GenerativeModel(
                model_name=self.config.model,
                generation_config=GenerationConfig(**self.config.to_generation_config()),
                safety_settings=safety_settings
            )
            
            self._initialized = True
            logger.info(f"Gemini client initialized: {self.config.model}")
            
        except Exception as e:
            logger.error(f"Failed to initialize Gemini client: {e}")
            raise GeminiAPIError(f"Client initialization failed: {e}") from e
    
    def _get_safety_settings(self) -> Dict[HarmCategory, HarmBlockThreshold]:
        """ã‚»ãƒ¼ãƒ•ãƒ†ã‚£è¨­å®šã‚’å–å¾—"""
        if self.config.safety_settings:
            return self.config.safety_settings
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ã‚»ãƒ¼ãƒ•ãƒ†ã‚£è¨­å®š
        return {
            HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_FEW,
            HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_FEW,
            HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_FEW,
            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_FEW,
        }
    
    async def generate_response(self, prompt: str) -> str:
        """
        Geminiã‹ã‚‰ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ç”Ÿæˆ
        
        Args:
            prompt: å…¥åŠ›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            
        Returns:
            ç”Ÿæˆã•ã‚ŒãŸãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ†ã‚­ã‚¹ãƒˆ
            
        Raises:
            GeminiAPIError: APIå‘¼ã³å‡ºã—ã«å¤±æ•—ã—ãŸå ´åˆ
        """
        if not self._initialized or not self._model:
            raise GeminiAPIError("Client not properly initialized")
        
        if not prompt or not prompt.strip():
            raise ValueError("Prompt cannot be empty")
        
        try:
            # éåŒæœŸã§APIå‘¼ã³å‡ºã—
            response = await asyncio.to_thread(
                self._model.generate_content,
                prompt.strip()
            )
            
            if not response.text:
                logger.warning("Empty response from Gemini API")
                return "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ãŒã€å›ç­”ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"
            
            return response.text.strip()
            
        except Exception as e:
            logger.error(f"Gemini API error: {e}")
            raise GeminiAPIError(f"Failed to generate response: {e}") from e
    
    async def generate_response_with_timeout(self, prompt: str, timeout: float = 5.0) -> str:
        """
        ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä»˜ãã§ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ç”Ÿæˆ
        
        Args:
            prompt: å…¥åŠ›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            timeout: ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆæ™‚é–“ï¼ˆç§’ï¼‰
            
        Returns:
            ç”Ÿæˆã•ã‚ŒãŸãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ†ã‚­ã‚¹ãƒˆ
        """
        try:
            return await asyncio.wait_for(
                self.generate_response(prompt),
                timeout=timeout
            )
        except asyncio.TimeoutError:
            logger.warning(f"Gemini API timeout after {timeout} seconds")
            return "å¿œç­”æ™‚é–“ãŒé•·ã™ãã¾ã™ã€‚ã‚ˆã‚Šç°¡æ½”ãªè³ªå•ã§ãŠè©¦ã—ãã ã•ã„ã€‚"
        except GeminiAPIError:
            return "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚AIã‚µãƒ¼ãƒ“ã‚¹ã«ä¸€æ™‚çš„ãªå•é¡ŒãŒç™ºç”Ÿã—ã¦ã„ã¾ã™ã€‚"
    
    async def health_check(self) -> bool:
        """
        Gemini API ã®æ¥ç¶šç¢ºèª
        
        Returns:
            æ¥ç¶šçŠ¶æ…‹ï¼ˆTrue=æ­£å¸¸, False=ç•°å¸¸ï¼‰
        """
        if not self._initialized:
            return False
            
        try:
            response = await self.generate_response_with_timeout(
                "Hello", timeout=3.0
            )
            return bool(response and len(response) > 0 and "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“" not in response)
            
        except Exception as e:
            logger.warning(f"Gemini health check failed: {e}")
            return False
    
    def get_client_info(self) -> Dict[str, Any]:
        """ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæƒ…å ±ã‚’å–å¾—"""
        return {
            "model": self.config.model,
            "temperature": self.config.temperature,
            "max_tokens": self.config.max_tokens,
            "initialized": self._initialized,
            "api_key_masked": self.config.get_masked_api_key()
        }
```

### 1.3 GeminiA2AAgent ã‚¯ãƒ©ã‚¹

```python
# app/a2a_prototype/agents/gemini_agent.py

import logging
from typing import List, Dict, Any

from a2a.types import AgentSkill

from ..utils.config import AgentConfig
from ..utils.gemini_client import GeminiClient, GeminiAPIError
from ..utils.gemini_config import GeminiConfig
from .base_agent import BaseA2AAgent

logger = logging.getLogger(__name__)

class GeminiA2AAgent(BaseA2AAgent):
    """Gemini 2.5 Pro ã‚’ä½¿ç”¨ã—ãŸA2Aã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"""
    
    # ã‚¯ãƒ©ã‚¹å®šæ•°
    MAX_CONTEXT_MESSAGES = 20  # ä¼šè©±å±¥æ­´ã®æœ€å¤§ä¿æŒæ•°ï¼ˆ10å¾€å¾©åˆ†ï¼‰
    MAX_INPUT_LENGTH = 10000   # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã®æœ€å¤§é•·
    
    def __init__(self, config: AgentConfig, gemini_config: GeminiConfig) -> None:
        """
        Args:
            config: A2Aã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­å®š
            gemini_config: Gemini APIè¨­å®š
        """
        super().__init__(config)
        self.gemini_config = gemini_config
        self.gemini_client = GeminiClient(gemini_config)
        self.conversation_context: List[str] = []
        
        # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå›ºæœ‰ã®ãƒ­ã‚°è¨­å®š
        self.logger = logging.getLogger(f"{__name__}.{config.name}")
        self.logger.info(f"Gemini agent initialized with model: {gemini_config.model}")
    
    def get_skills(self) -> List[AgentSkill]:
        """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã‚¹ã‚­ãƒ«ä¸€è¦§ã‚’å–å¾—"""
        return [
            AgentSkill(
                id="chat",
                name="intelligent_chat",
                description="Have an intelligent conversation using Gemini 2.5 Pro",
                tags=["conversation", "ai", "general"],
            ),
            AgentSkill(
                id="qa", 
                name="question_answering",
                description="Answer questions using advanced AI capabilities",
                tags=["qa", "knowledge", "research"],
            ),
            AgentSkill(
                id="help",
                name="help_assistant", 
                description="Provide help and guidance",
                tags=["help", "assistance", "guide"],
            ),
        ]
    
    async def process_user_input(self, user_input: str) -> str:
        """
        ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚’Gemini 2.5 Proã§å‡¦ç†
        
        Args:
            user_input: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ
            
        Returns:
            GeminiãŒç”Ÿæˆã—ãŸå¿œç­”ãƒ†ã‚­ã‚¹ãƒˆ
        """
        try:
            # å…¥åŠ›ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
            sanitized_input = self._sanitize_user_input(user_input)
            
            # ç‰¹åˆ¥ãªã‚³ãƒãƒ³ãƒ‰ã®å‡¦ç†
            if self._is_help_command(sanitized_input):
                return self._get_help_message()
            
            elif self._is_clear_command(sanitized_input):
                return self._clear_conversation_context()
            
            elif self._is_status_command(sanitized_input):
                return await self._get_status_message()
            
            # é€šå¸¸ã®å¯¾è©±å‡¦ç†
            prompt = self._build_conversation_prompt(sanitized_input)
            response = await self.gemini_client.generate_response_with_timeout(prompt)
            
            # ä¼šè©±å±¥æ­´ã‚’æ›´æ–°
            self._update_conversation_context(sanitized_input, response)
            
            return response
            
        except ValueError as e:
            self.logger.warning(f"Input validation error: {e}")
            return f"å…¥åŠ›ã‚¨ãƒ©ãƒ¼: {e}"
            
        except GeminiAPIError as e:
            self.logger.error(f"Gemini API error: {e}")
            return "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚AIã‚µãƒ¼ãƒ“ã‚¹ã«ä¸€æ™‚çš„ãªå•é¡ŒãŒç™ºç”Ÿã—ã¦ã„ã¾ã™ã€‚ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚"
            
        except Exception as e:
            self.logger.error(f"Unexpected error in process_user_input: {e}")
            return "äºˆæœŸã—ãªã„å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚"
    
    def _sanitize_user_input(self, user_input: str) -> str:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã®ã‚µãƒ‹ã‚¿ã‚¤ã‚º"""
        if not user_input:
            raise ValueError("å…¥åŠ›ãŒç©ºã§ã™")
        
        sanitized = user_input.strip()
        
        if len(sanitized) > self.MAX_INPUT_LENGTH:
            raise ValueError(f"å…¥åŠ›ãŒé•·ã™ãã¾ã™ï¼ˆæœ€å¤§{self.MAX_INPUT_LENGTH}æ–‡å­—ï¼‰")
        
        return sanitized
    
    def _is_help_command(self, input_text: str) -> bool:
        """ãƒ˜ãƒ«ãƒ—ã‚³ãƒãƒ³ãƒ‰ã‹ã©ã†ã‹åˆ¤å®š"""
        return input_text.lower() in ["help", "?", "ãƒ˜ãƒ«ãƒ—"]
    
    def _is_clear_command(self, input_text: str) -> bool:
        """ã‚¯ãƒªã‚¢ã‚³ãƒãƒ³ãƒ‰ã‹ã©ã†ã‹åˆ¤å®š"""
        return input_text.lower() in ["clear", "ã‚¯ãƒªã‚¢", "ãƒªã‚»ãƒƒãƒˆ"]
    
    def _is_status_command(self, input_text: str) -> bool:
        """ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒãƒ³ãƒ‰ã‹ã©ã†ã‹åˆ¤å®š"""
        return input_text.lower() in ["status", "ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", "çŠ¶æ…‹"]
    
    def _build_conversation_prompt(self, user_input: str) -> str:
        """ä¼šè©±å±¥æ­´ã‚’è€ƒæ…®ã—ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰"""
        base_prompt = (
            "ã‚ãªãŸã¯è¦ªåˆ‡ã§çŸ¥è­˜è±Šå¯ŒãªAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"
            "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã—ã¦ã€æ­£ç¢ºã§æœ‰ç”¨ãªå›ç­”ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚"
            "å›ç­”ã¯åˆ†ã‹ã‚Šã‚„ã™ãã€é©åº¦ãªé•·ã•ã§è¡Œã£ã¦ãã ã•ã„ã€‚\n\n"
        )
        
        # ä¼šè©±å±¥æ­´ãŒã‚ã‚Œã°è¿½åŠ ï¼ˆæœ€æ–°6ä»¶=3å¾€å¾©åˆ†ï¼‰
        if self.conversation_context:
            recent_context = self.conversation_context[-6:]
            conversation_history = "\n".join(recent_context)
            base_prompt += f"ä¼šè©±å±¥æ­´:\n{conversation_history}\n\n"
        
        base_prompt += f"ãƒ¦ãƒ¼ã‚¶ãƒ¼: {user_input}\nã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ: "
        
        return base_prompt
    
    def _update_conversation_context(self, user_input: str, ai_response: str) -> None:
        """ä¼šè©±å±¥æ­´ã‚’æ›´æ–°"""
        self.conversation_context.extend([
            f"User: {user_input}",
            f"Assistant: {ai_response}"
        ])
        
        # ä¸Šé™ã‚’è¶…ãˆãŸå ´åˆã¯å¤ã„å±¥æ­´ã‚’å‰Šé™¤
        if len(self.conversation_context) > self.MAX_CONTEXT_MESSAGES:
            self.conversation_context = self.conversation_context[-self.MAX_CONTEXT_MESSAGES:]
    
    def _clear_conversation_context(self) -> str:
        """ä¼šè©±å±¥æ­´ã‚’ã‚¯ãƒªã‚¢"""
        self.conversation_context.clear()
        return "âœ… ä¼šè©±å±¥æ­´ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸã€‚æ–°ã—ã„ä¼šè©±ã‚’å§‹ã‚ã¾ã—ã‚‡ã†ï¼"
    
    async def _get_status_message(self) -> str:
        """ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç”Ÿæˆ"""
        health = await self.gemini_client.health_check()
        client_info = self.gemini_client.get_client_info()
        
        return (
            f"ğŸ¤– {self.config.name}\n"
            f"ğŸ“¡ URL: {self.config.url}\n"
            f"ğŸ§  Model: {client_info['model']}\n"
            f"ğŸŒ¡ï¸ Temperature: {client_info['temperature']}\n"
            f"ğŸ“ Max Tokens: {client_info['max_tokens']}\n"
            f"ğŸ’š Status: {'âœ… OK' if health else 'âŒ ERROR'}\n"
            f"ğŸ’¬ Context: {len(self.conversation_context)} messages\n"
            f"ğŸ”‘ API Key: {client_info['api_key_masked']}"
        )
    
    def _get_help_message(self) -> str:
        """ãƒ˜ãƒ«ãƒ—ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç”Ÿæˆ"""
        return (
            f"ğŸ¤– **{self.config.name}** - Gemini 2.5 Proæ­è¼‰ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n"
            "ğŸ“ **ä½¿ã„æ–¹:**\n"
            "â€¢ è³ªå•ã‚„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è‡ªç”±ã«é€ä¿¡ã—ã¦ãã ã•ã„\n"
            "â€¢ `status` - ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®çŠ¶æ…‹ç¢ºèª\n"
            "â€¢ `clear` - ä¼šè©±å±¥æ­´ã‚’ã‚¯ãƒªã‚¢\n"
            "â€¢ `help` - ã“ã®ãƒ˜ãƒ«ãƒ—ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º\n\n"
            "ğŸ§  **ç‰¹å¾´:**\n"
            "â€¢ Google Gemini 2.5 Proã«ã‚ˆã‚‹é«˜åº¦ãªå¯¾è©±\n"
            "â€¢ ä¼šè©±å±¥æ­´ã‚’è€ƒæ…®ã—ãŸæ–‡è„ˆç†è§£\n"
            "â€¢ A2Aãƒ—ãƒ­ãƒˆã‚³ãƒ«å®Œå…¨æº–æ‹ \n"
            "â€¢ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¿œç­”\n\n"
            "ğŸ’¡ **æŠ€è¡“ä»•æ§˜:**\n"
            f"â€¢ Model: {self.gemini_config.model}\n"
            f"â€¢ Temperature: {self.gemini_config.temperature}\n"
            f"â€¢ Max Context: {self.MAX_CONTEXT_MESSAGES // 2} å¾€å¾©\n\n"
            "ä½•ã§ã‚‚ãŠæ°—è»½ã«ãŠèã‹ã›ãã ã•ã„ï¼âœ¨"
        )
    
    def get_agent_stats(self) -> Dict[str, Any]:
        """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®çµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
        return {
            "conversation_messages": len(self.conversation_context),
            "max_context_messages": self.MAX_CONTEXT_MESSAGES,
            "gemini_model": self.gemini_config.model,
            "gemini_temperature": self.gemini_config.temperature,
            "skills_count": len(self.get_skills()),
        }
```

## 2. ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°è¨­è¨ˆ

### 2.1 ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä½œæˆãƒ˜ãƒ«ãƒ‘ãƒ¼

```python
# app/a2a_prototype/agents/__init__.py ã¸ã®è¿½åŠ 

from .gemini_agent import GeminiA2AAgent

def create_gemini_agent(port: int = 8004, **kwargs) -> GeminiA2AAgent:
    """
    Geminiã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œæˆ
    
    Args:
        port: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒãƒ¼ãƒˆç•ªå·
        **kwargs: è¿½åŠ ã®è¨­å®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        
    Returns:
        è¨­å®šæ¸ˆã¿ã®GeminiA2AAgent
        
    Raises:
        ValueError: ç’°å¢ƒå¤‰æ•°ãŒä¸è¶³ã—ã¦ã„ã‚‹å ´åˆ
        GeminiConfigError: Geminiè¨­å®šã«å•é¡ŒãŒã‚ã‚‹å ´åˆ
    """
    from ..utils.config import AgentConfig
    from ..utils.gemini_config import GeminiConfig
    
    # A2Aã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­å®š
    agent_config = AgentConfig(
        name=kwargs.get("name", "gemini-chat-agent"),
        description=kwargs.get("description", "Advanced conversational AI agent powered by Gemini 2.5 Pro"),
        url=f"http://localhost:{port}",
        port=port,
        version=kwargs.get("version", "1.0.0")
    )
    
    # Geminiè¨­å®šï¼ˆç’°å¢ƒå¤‰æ•°ã‹ã‚‰èª­ã¿è¾¼ã¿ï¼‰
    gemini_config = GeminiConfig.from_env()
    
    # ã‚«ã‚¹ã‚¿ãƒ è¨­å®šã®ä¸Šæ›¸ã
    if "temperature" in kwargs:
        gemini_config.temperature = kwargs["temperature"]
    if "max_tokens" in kwargs:
        gemini_config.max_tokens = kwargs["max_tokens"]
    if "model" in kwargs:
        gemini_config.model = kwargs["model"]
    
    return GeminiA2AAgent(agent_config, gemini_config)
```

### 2.2 å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ

```python
# scripts/run_gemini_agent.py

"""
Gemini A2A Agent å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import asyncio
import logging
import os
import sys
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

from app.a2a_prototype.agents import create_gemini_agent

def setup_logging() -> None:
    """ãƒ­ã‚°è¨­å®šã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler('gemini_agent.log')
        ]
    )

async def main() -> None:
    """Geminiã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’èµ·å‹•"""
    
    setup_logging()
    logger = logging.getLogger(__name__)
    
    try:
        # ç’°å¢ƒå¤‰æ•°ç¢ºèª
        if not os.getenv("GEMINI_API_KEY"):
            print("âŒ GEMINI_API_KEY environment variable is required")
            print("ğŸ”§ Set it with: export GEMINI_API_KEY='your-api-key'")
            print("ğŸ’¡ Get your API key from: https://makersuite.google.com/app/apikey")
            return
        
        # Geminiã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä½œæˆ
        agent = create_gemini_agent(port=8004)
        
        print(f"ğŸš€ Starting {agent.config.name}...")
        print(f"ğŸ“¡ URL: {agent.config.url}")
        print(f"ğŸ§  Model: {agent.gemini_config.model}")
        print(f"ğŸŒ¡ï¸ Temperature: {agent.gemini_config.temperature}")
        print(f"ğŸ’¡ Test at: {agent.config.url}/.well-known/agent.json")
        print(f"ğŸ“Š Health check: {agent.config.url}/health")
        print("\nğŸ’¬ Ready for A2A conversations!")
        
        # ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ
        health = await agent.gemini_client.health_check()
        if health:
            print("âœ… Gemini API connection verified")
        else:
            print("âš ï¸ Warning: Gemini API health check failed")
        
        # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆèµ·å‹•
        agent.run_agent(host="0.0.0.0", port=8004)
        
    except KeyboardInterrupt:
        print("\nğŸ‘‹ Agent stopped by user.")
    except Exception as e:
        logger.error(f"Failed to start agent: {e}")
        print(f"âŒ Error: {e}")
        return

if __name__ == "__main__":
    asyncio.run(main())
```

## 3. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°è©³ç´°

### 3.1 ã‚«ã‚¹ã‚¿ãƒ ä¾‹å¤–ã‚¯ãƒ©ã‚¹

```python
# app/a2a_prototype/exceptions.py

"""ã‚«ã‚¹ã‚¿ãƒ ä¾‹å¤–ã‚¯ãƒ©ã‚¹å®šç¾©"""

class GeminiA2AError(Exception):
    """Gemini A2A ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé–¢é€£ã®ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼"""
    pass

class GeminiConfigError(GeminiA2AError):
    """Geminiè¨­å®šé–¢é€£ã®ã‚¨ãƒ©ãƒ¼"""
    pass

class GeminiAPIError(GeminiA2AError):
    """Gemini APIé€šä¿¡é–¢é€£ã®ã‚¨ãƒ©ãƒ¼"""
    pass

class A2AProtocolError(GeminiA2AError):
    """A2Aãƒ—ãƒ­ãƒˆã‚³ãƒ«é–¢é€£ã®ã‚¨ãƒ©ãƒ¼"""
    pass
```

## 4. ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãƒ»ãƒ•ã‚£ã‚¯ã‚¹ãƒãƒ£è¨­è¨ˆ

### 4.1 ãƒ†ã‚¹ãƒˆè¨­å®š

```python
# tests/fixtures/gemini_fixtures.py

import pytest
from unittest.mock import AsyncMock, MagicMock

from app.a2a_prototype.utils.gemini_config import GeminiConfig
from app.a2a_prototype.utils.config import AgentConfig
from app.a2a_prototype.utils.gemini_client import GeminiClient

@pytest.fixture
def test_gemini_config():
    """ãƒ†ã‚¹ãƒˆç”¨Geminiè¨­å®š"""
    return GeminiConfig(
        api_key="test-api-key-12345678",
        model="gemini-2.5-pro-preview-05-06",
        temperature=0.5,
        max_tokens=500
    )

@pytest.fixture
def test_agent_config():
    """ãƒ†ã‚¹ãƒˆç”¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­å®š"""
    return AgentConfig(
        name="test-gemini-agent",
        description="Test Gemini agent",
        url="http://localhost:8999",
        port=8999
    )

@pytest.fixture
def mock_gemini_client():
    """ãƒ¢ãƒƒã‚¯ã•ã‚ŒãŸGeminiClient"""
    client = AsyncMock(spec=GeminiClient)
    client.generate_response.return_value = "Test response from Gemini"
    client.generate_response_with_timeout.return_value = "Test response with timeout"
    client.health_check.return_value = True
    client.get_client_info.return_value = {
        "model": "gemini-2.5-pro-preview-05-06",
        "temperature": 0.7,
        "max_tokens": 1000,
        "initialized": True,
        "api_key_masked": "test-api********"
    }
    return client

@pytest.fixture 
def mock_genai():
    """ãƒ¢ãƒƒã‚¯ã•ã‚ŒãŸgoogle.generativeai"""
    with patch('google.generativeai.configure') as mock_configure, \
         patch('google.generativeai.GenerativeModel') as mock_model:
        
        mock_response = MagicMock()
        mock_response.text = "Mocked Gemini response"
        
        mock_model_instance = MagicMock()
        mock_model_instance.generate_content.return_value = mock_response
        mock_model.return_value = mock_model_instance
        
        yield {
            'configure': mock_configure,
            'model_class': mock_model,
            'model_instance': mock_model_instance,
            'response': mock_response
        }
```

---

**ä½œæˆæ—¥**: 2025-01-XX  
**ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: 1.0  
**æ‰¿èª**: TBD 