# Git Worktreeä¸¦åˆ—å®Ÿè¡Œæ–¹å¼ - æ­£å¼ãƒ«ãƒ¼ãƒ«æ•´å‚™æ–‡æ›¸

**æ–‡æ›¸ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: 1.0.0  
**åˆ¶å®šæ—¥**: 2025-06-07  
**é©ç”¨å¯¾è±¡**: Claude CLIä¸¦åˆ—å®Ÿè¡Œç’°å¢ƒ  
**å“è³ªåŸºæº–**: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒ«100%æº–æ‹ 

## ğŸ“‹ ç›®æ¬¡

1. [åŸºæœ¬åŸå‰‡](#åŸºæœ¬åŸå‰‡)
2. [ç’°å¢ƒæ§‹ç¯‰ãƒ«ãƒ¼ãƒ«](#ç’°å¢ƒæ§‹ç¯‰ãƒ«ãƒ¼ãƒ«)
3. [å®Ÿè¡Œãƒ«ãƒ¼ãƒ«](#å®Ÿè¡Œãƒ«ãƒ¼ãƒ«)
4. [å®‰å…¨ãƒ—ãƒ­ãƒˆã‚³ãƒ«](#å®‰å…¨ãƒ—ãƒ­ãƒˆã‚³ãƒ«)
5. [å“è³ªä¿è¨¼ãƒ«ãƒ¼ãƒ«](#å“è³ªä¿è¨¼ãƒ«ãƒ¼ãƒ«)
6. [ç›£è¦–ãƒ»æ¤œè¨¼ãƒ«ãƒ¼ãƒ«](#ç›£è¦–æ¤œè¨¼ãƒ«ãƒ¼ãƒ«)
7. [ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãƒ«ãƒ¼ãƒ«](#ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãƒ«ãƒ¼ãƒ«)
8. [å®Ÿè·µãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ](#å®Ÿè·µãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ)
9. [ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°](#ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°)
10. [ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ](#ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ)

## ğŸ¯ åŸºæœ¬åŸå‰‡

### åŸå‰‡1: ç‰©ç†çš„åˆ†é›¢ã®åŸå‰‡
**ã™ã¹ã¦ã®ä¸¦åˆ—ã‚¿ã‚¹ã‚¯ã¯ç‰©ç†çš„ã«ç‹¬ç«‹ã—ãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã§å®Ÿè¡Œã™ã‚‹**
- Git worktreeã«ã‚ˆã‚‹å®Œå…¨ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ åˆ†é›¢
- å„ã‚¿ã‚¹ã‚¯ã«å°‚ç”¨ã®ãƒ–ãƒ©ãƒ³ãƒã‚’å‰²ã‚Šå½“ã¦
- ãƒ•ã‚¡ã‚¤ãƒ«ç«¶åˆã®å¯èƒ½æ€§ã‚’0%ã«å‰Šæ¸›

### åŸå‰‡2: æ˜ç¤ºçš„ç®¡ç†ã®åŸå‰‡
**ã™ã¹ã¦ã®ä¸¦åˆ—å®Ÿè¡Œç’°å¢ƒã¯æ˜ç¤ºçš„ã«ä½œæˆãƒ»ç®¡ç†ãƒ»å‰Šé™¤ã™ã‚‹**
- è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸworktreeåã®ç¦æ­¢
- è¿½è·¡å¯èƒ½ãªå‘½åè¦å‰‡ã®å¼·åˆ¶
- ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã®ç¾©å‹™åŒ–

### åŸå‰‡3: å“è³ªç¶­æŒã®åŸå‰‡
**ä¸¦åˆ—å®Ÿè¡Œã«ãŠã„ã¦ã‚‚ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå“è³ªåŸºæº–ã‚’100%ç¶­æŒã™ã‚‹**
- å„worktreeã§ç‹¬ç«‹ã—ãŸå“è³ªãƒã‚§ãƒƒã‚¯
- TDDå®Ÿè·µã®ç¶™ç¶š
- ã‚«ãƒãƒ¬ãƒƒã‚¸åŸºæº–ã®éµå®ˆ

### åŸå‰‡4: ãƒˆãƒ¬ãƒ¼ã‚µãƒ“ãƒªãƒ†ã‚£ã®åŸå‰‡
**ã™ã¹ã¦ã®ä¸¦åˆ—å®Ÿè¡Œã¯è¿½è·¡ãƒ»ç›£æŸ»å¯èƒ½ã§ãªã‘ã‚Œã°ãªã‚‰ãªã„**
- å®Ÿè¡Œãƒ­ã‚°ã®ä¿å­˜
- ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®åé›†
- å®Ÿè¡Œå±¥æ­´ã®è¨˜éŒ²

## ğŸ“ ç’°å¢ƒæ§‹ç¯‰ãƒ«ãƒ¼ãƒ«

### Rule 1: Worktreeãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ 

```bash
project_root/
â”œâ”€â”€ worker/                    # Worktreeå°‚ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆå¿…é ˆï¼‰
â”‚   â”œâ”€â”€ feature_XXX_YYY/      # æ©Ÿèƒ½é–‹ç™ºç”¨worktree
â”‚   â”œâ”€â”€ bugfix_XXX_YYY/       # ãƒã‚°ä¿®æ­£ç”¨worktree
â”‚   â””â”€â”€ refactor_XXX_YYY/     # ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ç”¨worktree
â”œâ”€â”€ logs/                      # å®Ÿè¡Œãƒ­ã‚°ä¿å­˜ç”¨
â”‚   â””â”€â”€ parallel_execution/    # ä¸¦åˆ—å®Ÿè¡Œå°‚ç”¨ãƒ­ã‚°
â””â”€â”€ .gitignore                 # worker/ã‚’å¿…ãšè¿½åŠ 
```

**å¿…é ˆè¨­å®š**:
```bash
# .gitignoreã¸ã®è¿½åŠ ï¼ˆå¿…é ˆï¼‰
echo "worker/" >> .gitignore
echo "logs/parallel_execution/" >> .gitignore
```

### Rule 2: å‘½åè¦å‰‡

```bash
# Worktreeå‘½åè¦å‰‡
${type}_${id}_${description}

# ä¾‹:
feature_001_user_authentication
bugfix_042_memory_leak_fix
refactor_003_database_optimization

# ãƒ–ãƒ©ãƒ³ãƒå‘½åè¦å‰‡
${type}/${component}-${functionality}

# ä¾‹:
feature/auth-jwt-implementation
bugfix/payment-validation-error
refactor/database-query-optimization
```

### Rule 3: ç’°å¢ƒæ¤œè¨¼

```bash
# Worktreeä½œæˆå‰ã®å¿…é ˆãƒã‚§ãƒƒã‚¯
verify_worktree_environment() {
    # 1. ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå­˜åœ¨ç¢ºèª
    [ -d "worker" ] || mkdir -p worker
    
    # 2. GitçŠ¶æ…‹ç¢ºèª
    git status --porcelain | grep -q . && {
        echo "Error: Working directory not clean"
        return 1
    }
    
    # 3. ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ç¢ºèªï¼ˆæœ€ä½1GB/worktreeï¼‰
    available_space=$(df -BG . | awk 'NR==2 {print $4}' | sed 's/G//')
    [ "$available_space" -lt 3 ] && {
        echo "Error: Insufficient disk space"
        return 1
    }
    
    return 0
}
```

## ğŸš€ å®Ÿè¡Œãƒ«ãƒ¼ãƒ«

### Rule 4: ã‚¿ã‚¹ã‚¯åˆ†è§£åŸºæº–

```mermaid
graph TD
    A[ãƒ¡ã‚¤ãƒ³ã‚¿ã‚¹ã‚¯] --> B{ä¸¦åˆ—åŒ–å¯èƒ½?}
    B -->|Yes| C[ç‹¬ç«‹æ€§ãƒã‚§ãƒƒã‚¯]
    B -->|No| D[ç›´åˆ—å®Ÿè¡Œ]
    
    C --> E{ãƒ•ã‚¡ã‚¤ãƒ«ç«¶åˆ?}
    E -->|No| F[ä¸¦åˆ—å®Ÿè¡Œæ‰¿èª]
    E -->|Yes| G[ã‚¿ã‚¹ã‚¯å†è¨­è¨ˆ]
    
    F --> H[Worktreeä½œæˆ]
    H --> I[ä¸¦åˆ—å®Ÿè¡Œ]
```

**ä¸¦åˆ—åŒ–å¯èƒ½æ¡ä»¶**:
1. ã‚¿ã‚¹ã‚¯é–“ã§ãƒ•ã‚¡ã‚¤ãƒ«ç·¨é›†ã®é‡è¤‡ãŒãªã„
2. å®Ÿè¡Œé †åºã«ä¾å­˜é–¢ä¿‚ãŒãªã„
3. ãƒªã‚½ãƒ¼ã‚¹ç«¶åˆãŒç™ºç”Ÿã—ãªã„
4. å„ã‚¿ã‚¹ã‚¯ãŒç‹¬ç«‹ã—ã¦ãƒ†ã‚¹ãƒˆå¯èƒ½

### Rule 5: å®Ÿè¡Œãƒ‘ã‚¿ãƒ¼ãƒ³

#### ãƒ‘ã‚¿ãƒ¼ãƒ³A: ã‚·ãƒ³ãƒ—ãƒ«ä¸¦åˆ—å®Ÿè¡Œ
```bash
#!/bin/bash
# parallel_simple.sh

# ã‚¿ã‚¹ã‚¯å®šç¾©
TASKS=(
    "feature_001_auth:ãƒ¦ãƒ¼ã‚¶ãƒ¼èªè¨¼æ©Ÿèƒ½ã®å®Ÿè£…"
    "feature_002_payment:æ±ºæ¸ˆå‡¦ç†ã®å®Ÿè£…"
    "feature_003_notification:é€šçŸ¥ã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿè£…"
)

# Worktreeä½œæˆã¨å®Ÿè¡Œ
for task_spec in "${TASKS[@]}"; do
    IFS=':' read -r task_name task_desc <<< "$task_spec"
    
    # Worktreeä½œæˆ
    git worktree add "worker/${task_name}" -b "${task_name}"
    
    # ä¸¦åˆ—å®Ÿè¡Œ
    (
        cd "worker/${task_name}"
        echo "[$(date)] Starting: ${task_desc}" >> ../../logs/parallel_execution.log
        claude -p "${task_desc}"
        echo "[$(date)] Completed: ${task_desc}" >> ../../logs/parallel_execution.log
    ) &
done

# å…¨ã‚¿ã‚¹ã‚¯å®Œäº†å¾…æ©Ÿ
wait
echo "All parallel tasks completed"
```

#### ãƒ‘ã‚¿ãƒ¼ãƒ³B: æ®µéšçš„ä¸¦åˆ—å®Ÿè¡Œ
```bash
#!/bin/bash
# parallel_phased.sh

# Phase 1: åˆ†æã‚¿ã‚¹ã‚¯ï¼ˆèª­ã¿å–ã‚Šå°‚ç”¨ï¼‰
echo "=== Phase 1: Analysis ==="
analysis_tasks=(
    "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è„†å¼±æ€§ã®åˆ†æ"
    "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã®åˆ†æ"
    "ã‚³ãƒ¼ãƒ‰å“è³ªã®åˆ†æ"
)

for i in "${!analysis_tasks[@]}"; do
    (
        cd worker/analysis_$((i+1))
        claude -p "${analysis_tasks[$i]}" > "analysis_report_$((i+1)).md"
    ) &
done
wait

# Phase 2: å®Ÿè£…ã‚¿ã‚¹ã‚¯ï¼ˆåˆ†æçµæœåŸºã¥ãï¼‰
echo "=== Phase 2: Implementation ==="
implementation_tasks=(
    "analysis_report_1.mdã‚’åŸºã«ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ä¿®æ­£ã‚’å®Ÿè£…"
    "analysis_report_2.mdã‚’åŸºã«æœ€é©åŒ–ã‚’å®Ÿè£…"
    "analysis_report_3.mdã‚’åŸºã«ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ã‚’å®Ÿè£…"
)

for i in "${!implementation_tasks[@]}"; do
    git worktree add "worker/impl_$((i+1))" -b "feature/impl-$((i+1))"
    (
        cd "worker/impl_$((i+1))"
        claude -p "${implementation_tasks[$i]}"
    ) &
done
wait

# Phase 3: æ¤œè¨¼ã‚¿ã‚¹ã‚¯
echo "=== Phase 3: Verification ==="
# å„å®Ÿè£…ã®å“è³ªæ¤œè¨¼
```

### Rule 6: ä¸¦åˆ—åº¦åˆ¶é™

```python
# parallel_executor.py
import asyncio
from asyncio import Semaphore
import multiprocessing

class ParallelExecutor:
    def __init__(self):
        # CPUæ•°ã«åŸºã¥ãä¸¦åˆ—åº¦æ±ºå®š
        cpu_count = multiprocessing.cpu_count()
        self.max_parallel = min(cpu_count - 1, 4)  # æœ€å¤§4ä¸¦åˆ—
        self.semaphore = Semaphore(self.max_parallel)
    
    async def execute_task(self, worktree_path: str, prompt: str):
        async with self.semaphore:
            # ãƒªã‚½ãƒ¼ã‚¹åˆ¶é™ä¸‹ã§ã‚¿ã‚¹ã‚¯å®Ÿè¡Œ
            process = await asyncio.create_subprocess_exec(
                'claude', '-p', prompt,
                cwd=worktree_path,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            stdout, stderr = await process.communicate()
            return process.returncode, stdout, stderr
```

## ğŸ›¡ï¸ å®‰å…¨ãƒ—ãƒ­ãƒˆã‚³ãƒ«

### Rule 7: äº‹å‰ç«¶åˆãƒã‚§ãƒƒã‚¯

```bash
# check_conflicts.sh
#!/bin/bash

check_file_conflicts() {
    local -a tasks=("$@")
    local -a all_files=()
    
    for task in "${tasks[@]}"; do
        # ã‚¿ã‚¹ã‚¯ãŒå½±éŸ¿ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¨å®š
        echo "Analyzing task: $task"
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¨å®š
        if [[ "$task" =~ "auth" ]]; then
            all_files+=("app/a2a/auth.py" "tests/test_auth.py")
        elif [[ "$task" =~ "payment" ]]; then
            all_files+=("app/a2a/payment.py" "tests/test_payment.py")
        fi
    done
    
    # é‡è¤‡ãƒã‚§ãƒƒã‚¯
    duplicates=$(printf '%s\n' "${all_files[@]}" | sort | uniq -d)
    if [ -n "$duplicates" ]; then
        echo "âŒ File conflicts detected:"
        echo "$duplicates"
        return 1
    fi
    
    echo "âœ… No file conflicts detected"
    return 0
}
```

### Rule 8: å®Ÿè¡Œç›£è¦–

```python
# monitor_execution.py
import psutil
import time
import json
from pathlib import Path

class ExecutionMonitor:
    def __init__(self, log_dir: Path):
        self.log_dir = log_dir
        self.metrics = []
    
    def monitor_resources(self):
        """ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨çŠ¶æ³ã®ç›£è¦–"""
        while True:
            metric = {
                "timestamp": time.time(),
                "cpu_percent": psutil.cpu_percent(interval=1),
                "memory_percent": psutil.virtual_memory().percent,
                "disk_io": psutil.disk_io_counters()._asdict(),
                "active_processes": len(psutil.pids())
            }
            
            self.metrics.append(metric)
            
            # é–¾å€¤ãƒã‚§ãƒƒã‚¯
            if metric["cpu_percent"] > 90:
                self.alert("High CPU usage detected")
            if metric["memory_percent"] > 85:
                self.alert("High memory usage detected")
            
            time.sleep(10)  # 10ç§’ã”ã¨ã«ç›£è¦–
    
    def save_metrics(self):
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ä¿å­˜"""
        output_file = self.log_dir / f"metrics_{int(time.time())}.json"
        with open(output_file, 'w') as f:
            json.dump(self.metrics, f, indent=2)
```

### Rule 9: ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

```bash
# error_handler.sh
#!/bin/bash

execute_with_rollback() {
    local worktree_path=$1
    local task_name=$2
    local prompt=$3
    
    # å®Ÿè¡Œå‰ã®ã‚³ãƒŸãƒƒãƒˆIDã‚’è¨˜éŒ²
    original_commit=$(git -C "$worktree_path" rev-parse HEAD)
    
    # ã‚¿ã‚¹ã‚¯å®Ÿè¡Œ
    cd "$worktree_path"
    if ! claude -p "$prompt"; then
        echo "âŒ Task failed: $task_name"
        
        # ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯
        git reset --hard "$original_commit"
        git clean -fd
        
        # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°è¨˜éŒ²
        echo "[ERROR] $(date): Task $task_name failed and rolled back" >> ../logs/errors.log
        return 1
    fi
    
    echo "âœ… Task completed: $task_name"
    return 0
}
```

## âœ… å“è³ªä¿è¨¼ãƒ«ãƒ¼ãƒ«

### Rule 10: ä¸¦åˆ—å“è³ªãƒã‚§ãƒƒã‚¯

```bash
# parallel_quality_check.sh
#!/bin/bash

run_quality_checks() {
    local worktree_path=$1
    local results_dir="$worktree_path/quality_results"
    mkdir -p "$results_dir"
    
    echo "Running quality checks in $worktree_path"
    
    # å„ãƒã‚§ãƒƒã‚¯ã‚’ä¸¦åˆ—å®Ÿè¡Œ
    (
        cd "$worktree_path"
        
        # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
        pytest --cov=app --cov-report=json:"$results_dir/coverage.json" &
        
        # Flake8ãƒã‚§ãƒƒã‚¯
        flake8 app/ tests/ --output-file="$results_dir/flake8.txt" &
        
        # Black ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãƒã‚§ãƒƒã‚¯
        black app/ tests/ --check --diff > "$results_dir/black.txt" 2>&1 &
        
        # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯
        bandit -r app/ -f json -o "$results_dir/bandit.json" &
        
        wait
    )
    
    # çµæœé›†ç´„
    aggregate_quality_results "$results_dir"
}
```

### Rule 11: çµ±åˆå‰æ¤œè¨¼

```python
# integration_verifier.py
from pathlib import Path
import subprocess
import json

class IntegrationVerifier:
    def __init__(self, worktree_paths: list[Path]):
        self.worktree_paths = worktree_paths
        self.results = {}
    
    def verify_all_worktrees(self) -> bool:
        """å…¨worktreeã®æ¤œè¨¼"""
        all_passed = True
        
        for worktree in self.worktree_paths:
            print(f"Verifying {worktree}...")
            
            # å“è³ªãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ
            checks = {
                "tests": self.run_tests(worktree),
                "coverage": self.check_coverage(worktree),
                "linting": self.run_linting(worktree),
                "security": self.run_security_scan(worktree)
            }
            
            self.results[str(worktree)] = checks
            
            if not all(checks.values()):
                all_passed = False
                print(f"âŒ Verification failed for {worktree}")
            else:
                print(f"âœ… Verification passed for {worktree}")
        
        return all_passed
    
    def generate_report(self):
        """çµ±åˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        report_path = Path("integration_report.json")
        with open(report_path, 'w') as f:
            json.dump(self.results, f, indent=2)
        
        print(f"Integration report saved to {report_path}")
```

## ğŸ“Š ç›£è¦–ãƒ»æ¤œè¨¼ãƒ«ãƒ¼ãƒ«

### Rule 12: ãƒ­ã‚°ç®¡ç†

```bash
# log_structure.sh
logs/
â”œâ”€â”€ parallel_execution/
â”‚   â”œâ”€â”€ $(date +%Y%m%d)/           # æ—¥ä»˜åˆ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
â”‚   â”‚   â”œâ”€â”€ execution.log          # å®Ÿè¡Œãƒ­ã‚°
â”‚   â”‚   â”œâ”€â”€ errors.log             # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°
â”‚   â”‚   â”œâ”€â”€ metrics.json           # ãƒ¡ãƒˆãƒªã‚¯ã‚¹
â”‚   â”‚   â””â”€â”€ summary.md             # æ—¥æ¬¡ã‚µãƒãƒªãƒ¼
â”‚   â””â”€â”€ archive/                   # ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–æ¸ˆã¿ãƒ­ã‚°
```

### Rule 13: ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†

```python
# metrics_collector.py
class MetricsCollector:
    def __init__(self):
        self.metrics = {
            "execution_times": [],
            "resource_usage": [],
            "quality_scores": [],
            "error_rates": []
        }
    
    def collect_execution_metrics(self, worktree_name: str, start_time: float, end_time: float):
        """å®Ÿè¡Œãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®åé›†"""
        duration = end_time - start_time
        self.metrics["execution_times"].append({
            "worktree": worktree_name,
            "duration_seconds": duration,
            "timestamp": start_time
        })
    
    def generate_dashboard(self):
        """ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç”Ÿæˆ"""
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®å¯è¦–åŒ–
        pass
```

### Rule 14: å®šæœŸæ¤œè¨¼

```bash
# periodic_verification.sh
#!/bin/bash

daily_health_check() {
    echo "=== Daily Health Check $(date) ==="
    
    # 1. å­¤ç«‹worktreeã®æ¤œå‡º
    echo "Checking for orphaned worktrees..."
    git worktree prune --dry-run
    
    # 2. ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨é‡ç¢ºèª
    echo "Disk usage by worktrees:"
    du -sh worker/* 2>/dev/null | sort -hr
    
    # 3. æœªãƒãƒ¼ã‚¸ãƒ–ãƒ©ãƒ³ãƒã®ç¢ºèª
    echo "Unmerged feature branches:"
    git branch -r | grep "feature/" | while read branch; do
        if ! git branch --merged | grep -q "$branch"; then
            echo "  - $branch"
        fi
    done
    
    # 4. ãƒ­ã‚°ã‚µã‚¤ã‚ºç¢ºèª
    echo "Log sizes:"
    find logs/ -type f -name "*.log" -mtime +7 -exec ls -lh {} \;
}
```

## ğŸ§¹ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãƒ«ãƒ¼ãƒ«

### Rule 15: è‡ªå‹•ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—

```bash
# auto_cleanup.sh
#!/bin/bash

cleanup_completed_worktrees() {
    # ãƒãƒ¼ã‚¸æ¸ˆã¿worktreeã®è‡ªå‹•å‰Šé™¤
    for worktree in worker/*; do
        [ -d "$worktree" ] || continue
        
        branch_name=$(git -C "$worktree" branch --show-current)
        
        # ãƒãƒ¼ã‚¸ç¢ºèª
        if git branch --merged main | grep -q "$branch_name"; then
            echo "Removing merged worktree: $worktree"
            git worktree remove "$worktree" --force
            git branch -d "$branch_name"
        fi
    done
    
    # å¤ã„ãƒ­ã‚°ã®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–
    find logs/parallel_execution -type f -mtime +30 -exec gzip {} \;
    
    # Git GCå®Ÿè¡Œ
    git gc --auto
}
```

### Rule 16: ç·Šæ€¥ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—

```bash
# emergency_cleanup.sh
#!/bin/bash

force_cleanup_all() {
    echo "âš ï¸  Emergency cleanup initiated"
    
    # å…¨worktreeã®å¼·åˆ¶å‰Šé™¤
    git worktree list --porcelain | grep "^worktree" | cut -d' ' -f2 | \
    while read worktree_path; do
        if [[ "$worktree_path" == *"/worker/"* ]]; then
            echo "Removing: $worktree_path"
            git worktree remove "$worktree_path" --force
        fi
    done
    
    # workerãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å®Œå…¨å‰Šé™¤
    rm -rf worker/
    
    # Gitã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
    git worktree prune
    git gc --aggressive --prune=now
    
    echo "âœ… Emergency cleanup completed"
}
```

## ğŸ“ å®Ÿè·µãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ

### ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ1: åŸºæœ¬çš„ãªä¸¦åˆ—å®Ÿè¡Œ

```bash
#!/bin/bash
# template_basic_parallel.sh

set -euo pipefail

# è¨­å®š
PROJECT_ROOT=$(git rev-parse --show-toplevel)
WORKER_DIR="$PROJECT_ROOT/worker"
LOG_DIR="$PROJECT_ROOT/logs/parallel_execution/$(date +%Y%m%d)"

# åˆæœŸåŒ–
mkdir -p "$WORKER_DIR" "$LOG_DIR"

# ã‚¿ã‚¹ã‚¯å®šç¾©
declare -A TASKS=(
    ["feature_001"]="èªè¨¼ã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿè£…"
    ["feature_002"]="æ±ºæ¸ˆå‡¦ç†ã®å®Ÿè£…"
    ["feature_003"]="é€šçŸ¥æ©Ÿèƒ½ã®å®Ÿè£…"
)

# ãƒ¡ã‚¤ãƒ³å‡¦ç†
main() {
    echo "Starting parallel execution at $(date)" | tee "$LOG_DIR/execution.log"
    
    # ç’°å¢ƒæ¤œè¨¼
    verify_worktree_environment || exit 1
    
    # Worktreeä½œæˆã¨å®Ÿè¡Œ
    for task_id in "${!TASKS[@]}"; do
        create_and_execute_task "$task_id" "${TASKS[$task_id]}" &
    done
    
    # å®Œäº†å¾…æ©Ÿ
    wait
    
    # å“è³ªãƒã‚§ãƒƒã‚¯
    run_parallel_quality_checks
    
    # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    cleanup_completed_worktrees
    
    echo "Parallel execution completed at $(date)" | tee -a "$LOG_DIR/execution.log"
}

create_and_execute_task() {
    local task_id=$1
    local task_desc=$2
    local worktree_path="$WORKER_DIR/$task_id"
    
    # Worktreeä½œæˆ
    git worktree add "$worktree_path" -b "$task_id" 2>&1 | tee -a "$LOG_DIR/execution.log"
    
    # ã‚¿ã‚¹ã‚¯å®Ÿè¡Œ
    (
        cd "$worktree_path"
        echo "[$(date)] Starting: $task_desc" >> "$LOG_DIR/execution.log"
        
        if claude -p "$task_desc"; then
            echo "[$(date)] âœ… Completed: $task_desc" >> "$LOG_DIR/execution.log"
        else
            echo "[$(date)] âŒ Failed: $task_desc" >> "$LOG_DIR/execution.log"
        fi
    )
}

# å®Ÿè¡Œ
main "$@"
```

### ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ2: æ®µéšçš„ä¸¦åˆ—å®Ÿè¡Œ

```bash
#!/bin/bash
# template_phased_parallel.sh

# Phase 1: åˆ†æãƒ•ã‚§ãƒ¼ã‚º
run_analysis_phase() {
    local -a analysis_tasks=(
        "ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£åˆ†æ"
        "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã®ç‰¹å®š"
        "ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®æ”¹å–„ç‚¹åˆ†æ"
    )
    
    echo "=== Phase 1: Analysis Phase ==="
    
    for i in "${!analysis_tasks[@]}"; do
        local worktree="worker/analysis_$((i+1))"
        git worktree add "$worktree" -b "analysis-$((i+1))"
        
        (
            cd "$worktree"
            claude -p "${analysis_tasks[$i]}" > "report_$((i+1)).md"
        ) &
    done
    
    wait
}

# Phase 2: å®Ÿè£…ãƒ•ã‚§ãƒ¼ã‚º
run_implementation_phase() {
    echo "=== Phase 2: Implementation Phase ==="
    
    # åˆ†æçµæœã‚’åŸºã«å®Ÿè£…
    for i in {1..3}; do
        local worktree="worker/impl_$i"
        git worktree add "$worktree" -b "implementation-$i"
        
        (
            cd "$worktree"
            # åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ã‚³ãƒ”ãƒ¼
            cp "../analysis_$i/report_$i.md" .
            
            claude -p "report_$i.mdã®åˆ†æçµæœã‚’åŸºã«æ”¹å–„ã‚’å®Ÿè£…"
        ) &
    done
    
    wait
}

# Phase 3: çµ±åˆãƒ•ã‚§ãƒ¼ã‚º
run_integration_phase() {
    echo "=== Phase 3: Integration Phase ==="
    
    # å„å®Ÿè£…ã‚’ãƒãƒ¼ã‚¸
    for i in {1..3}; do
        git merge "implementation-$i" --no-ff -m "Merge implementation $i"
    done
    
    # çµ±åˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    python scripts/quality_gate_check.py
}

# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ
main() {
    run_analysis_phase
    run_implementation_phase
    run_integration_phase
}

main "$@"
```

### ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ3: é«˜åº¦ãªä¸¦åˆ—å®Ÿè¡Œç®¡ç†

```python
#!/usr/bin/env python3
# template_advanced_parallel.py

import asyncio
import subprocess
from pathlib import Path
from typing import List, Dict, Tuple
import json
import time

class AdvancedParallelExecutor:
    def __init__(self, project_root: Path):
        self.project_root = project_root
        self.worker_dir = project_root / "worker"
        self.log_dir = project_root / "logs" / "parallel_execution" / time.strftime("%Y%m%d")
        self.max_parallel = 3
        self.results = {}
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        self.worker_dir.mkdir(exist_ok=True)
        self.log_dir.mkdir(parents=True, exist_ok=True)
    
    async def execute_task(self, task_id: str, task_desc: str) -> Tuple[str, bool]:
        """å€‹åˆ¥ã‚¿ã‚¹ã‚¯ã®å®Ÿè¡Œ"""
        worktree_path = self.worker_dir / task_id
        
        try:
            # Worktreeä½œæˆ
            await self._run_command(
                ["git", "worktree", "add", str(worktree_path), "-b", task_id]
            )
            
            # Claudeå®Ÿè¡Œ
            start_time = time.time()
            process = await asyncio.create_subprocess_exec(
                "claude", "-p", task_desc,
                cwd=worktree_path,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            
            stdout, stderr = await process.communicate()
            end_time = time.time()
            
            # çµæœè¨˜éŒ²
            success = process.returncode == 0
            self.results[task_id] = {
                "success": success,
                "duration": end_time - start_time,
                "stdout": stdout.decode() if stdout else "",
                "stderr": stderr.decode() if stderr else ""
            }
            
            # å“è³ªãƒã‚§ãƒƒã‚¯
            if success:
                await self.run_quality_checks(worktree_path)
            
            return task_id, success
            
        except Exception as e:
            self.results[task_id] = {
                "success": False,
                "error": str(e)
            }
            return task_id, False
    
    async def run_quality_checks(self, worktree_path: Path):
        """å“è³ªãƒã‚§ãƒƒã‚¯ã®å®Ÿè¡Œ"""
        checks = [
            ["pytest", "--cov=app", "--cov-report=json"],
            ["flake8", "app/", "tests/"],
            ["black", "app/", "tests/", "--check"],
            ["mypy", "app/"]
        ]
        
        quality_results = {}
        
        for check_cmd in checks:
            process = await asyncio.create_subprocess_exec(
                *check_cmd,
                cwd=worktree_path,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            
            stdout, stderr = await process.communicate()
            quality_results[check_cmd[0]] = {
                "passed": process.returncode == 0,
                "output": stdout.decode() if stdout else stderr.decode()
            }
        
        # å“è³ªçµæœã‚’ä¿å­˜
        quality_file = worktree_path / "quality_results.json"
        with open(quality_file, 'w') as f:
            json.dump(quality_results, f, indent=2)
    
    async def execute_parallel(self, tasks: Dict[str, str]):
        """ä¸¦åˆ—å®Ÿè¡Œã®ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
        semaphore = asyncio.Semaphore(self.max_parallel)
        
        async def bounded_execute(task_id: str, task_desc: str):
            async with semaphore:
                return await self.execute_task(task_id, task_desc)
        
        # å…¨ã‚¿ã‚¹ã‚¯ã‚’ä¸¦åˆ—å®Ÿè¡Œ
        results = await asyncio.gather(
            *[bounded_execute(tid, tdesc) for tid, tdesc in tasks.items()],
            return_exceptions=True
        )
        
        # çµæœã‚µãƒãƒªãƒ¼
        successful = sum(1 for _, success in results if success)
        failed = len(results) - successful
        
        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        self.generate_report(successful, failed)
        
        return successful, failed
    
    def generate_report(self, successful: int, failed: int):
        """å®Ÿè¡Œãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""
        report = {
            "execution_date": time.strftime("%Y-%m-%d %H:%M:%S"),
            "total_tasks": successful + failed,
            "successful": successful,
            "failed": failed,
            "results": self.results
        }
        
        report_file = self.log_dir / "execution_report.json"
        with open(report_file, 'w') as f:
            json.dump(report, f, indent=2)
        
        # ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã‚µãƒãƒªãƒ¼
        summary_file = self.log_dir / "summary.md"
        with open(summary_file, 'w') as f:
            f.write(f"# ä¸¦åˆ—å®Ÿè¡Œã‚µãƒãƒªãƒ¼\n\n")
            f.write(f"å®Ÿè¡Œæ—¥æ™‚: {report['execution_date']}\n\n")
            f.write(f"## çµæœ\n")
            f.write(f"- æˆåŠŸ: {successful}\n")
            f.write(f"- å¤±æ•—: {failed}\n\n")
            
            f.write(f"## è©³ç´°\n")
            for task_id, result in self.results.items():
                status = "âœ…" if result.get("success") else "âŒ"
                f.write(f"- {status} {task_id}: ")
                if result.get("duration"):
                    f.write(f"{result['duration']:.2f}ç§’\n")
                else:
                    f.write(f"{result.get('error', 'Unknown error')}\n")
    
    async def cleanup(self):
        """ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å‡¦ç†"""
        # ãƒãƒ¼ã‚¸æ¸ˆã¿worktreeã®å‰Šé™¤
        for task_id in self.results:
            if self.results[task_id].get("success"):
                worktree_path = self.worker_dir / task_id
                if worktree_path.exists():
                    await self._run_command(
                        ["git", "worktree", "remove", str(worktree_path), "--force"]
                    )
    
    async def _run_command(self, cmd: List[str]):
        """ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œãƒ˜ãƒ«ãƒ‘ãƒ¼"""
        process = await asyncio.create_subprocess_exec(
            *cmd,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE
        )
        await process.communicate()
        return process.returncode == 0


# ä½¿ç”¨ä¾‹
async def main():
    # ã‚¿ã‚¹ã‚¯å®šç¾©
    tasks = {
        "feature_auth": "èªè¨¼ã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿè£…ï¼ˆJWTå¯¾å¿œï¼‰",
        "feature_payment": "æ±ºæ¸ˆå‡¦ç†ã®å®Ÿè£…ï¼ˆStripeçµ±åˆï¼‰",
        "feature_notification": "é€šçŸ¥ã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿè£…ï¼ˆEmail/SMSï¼‰"
    }
    
    # å®Ÿè¡Œ
    executor = AdvancedParallelExecutor(Path.cwd())
    successful, failed = await executor.execute_parallel(tasks)
    
    print(f"\nå®Ÿè¡Œå®Œäº†: æˆåŠŸ={successful}, å¤±æ•—={failed}")
    
    # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    await executor.cleanup()


if __name__ == "__main__":
    asyncio.run(main())
```

## ğŸ”§ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### å•é¡Œ1: Worktreeä½œæˆã‚¨ãƒ©ãƒ¼

**ç—‡çŠ¶**: `fatal: 'worker/xxx' already exists`

**è§£æ±ºç­–**:
```bash
# æ—¢å­˜worktreeã®ç¢ºèª
git worktree list

# å¼·åˆ¶å‰Šé™¤
git worktree remove worker/xxx --force

# å­¤ç«‹worktreeã®æ•´ç†
git worktree prune
```

### å•é¡Œ2: ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ä¸è¶³

**ç—‡çŠ¶**: `No space left on device`

**è§£æ±ºç­–**:
```bash
# Worktreeä½¿ç”¨é‡ç¢ºèª
du -sh worker/* | sort -hr

# ä¸è¦ãªworktreeå‰Šé™¤
for worktree in worker/*; do
    if git -C "$worktree" status --porcelain | grep -q .; then
        echo "Has changes: $worktree"
    else
        git worktree remove "$worktree"
    fi
done

# Git GCå®Ÿè¡Œ
git gc --aggressive --prune=now
```

### å•é¡Œ3: ä¸¦åˆ—å®Ÿè¡Œæ™‚ã®ãƒªã‚½ãƒ¼ã‚¹æ¯æ¸‡

**ç—‡çŠ¶**: ã‚·ã‚¹ãƒ†ãƒ ã®å¿œç­”ãŒé…ã„ã€ãƒ¡ãƒ¢ãƒªä¸è¶³

**è§£æ±ºç­–**:
```python
# ãƒªã‚½ãƒ¼ã‚¹ç›£è¦–ã¨åˆ¶é™
import resource

# ãƒ¡ãƒ¢ãƒªåˆ¶é™è¨­å®šï¼ˆ2GBï¼‰
resource.setrlimit(resource.RLIMIT_AS, (2 * 1024 * 1024 * 1024, -1))

# CPUå„ªå…ˆåº¦ã‚’ä¸‹ã’ã‚‹
import os
os.nice(10)
```

### å•é¡Œ4: ãƒãƒ¼ã‚¸ã‚³ãƒ³ãƒ•ãƒªã‚¯ãƒˆ

**ç—‡çŠ¶**: ä¸¦åˆ—é–‹ç™ºå¾Œã®ãƒãƒ¼ã‚¸ã§ã‚³ãƒ³ãƒ•ãƒªã‚¯ãƒˆç™ºç”Ÿ

**è§£æ±ºç­–**:
```bash
# ã‚³ãƒ³ãƒ•ãƒªã‚¯ãƒˆè§£æ±ºæ‰‹é †
git merge feature/task-01 --no-ff

# ã‚³ãƒ³ãƒ•ãƒªã‚¯ãƒˆç¢ºèª
git status

# ãƒ•ã‚¡ã‚¤ãƒ«å˜ä½ã§è§£æ±º
git checkout --theirs path/to/file  # ç›¸æ‰‹ã®å¤‰æ›´ã‚’æ¡ç”¨
git checkout --ours path/to/file    # è‡ªåˆ†ã®å¤‰æ›´ã‚’ç¶­æŒ

# ã¾ãŸã¯æ‰‹å‹•ç·¨é›†å¾Œ
git add path/to/file
git commit
```

## âœ… ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

### å®Ÿè¡Œå‰ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

- [ ] Gitä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒã‚¯ãƒªãƒ¼ãƒ³ã‹ç¢ºèª
- [ ] worker/ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒ.gitignoreã«è¿½åŠ ã•ã‚Œã¦ã„ã‚‹ã‹
- [ ] ååˆ†ãªãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ãŒã‚ã‚‹ã‹ï¼ˆæœ€ä½3GBï¼‰
- [ ] ã‚¿ã‚¹ã‚¯é–“ã®ä¾å­˜é–¢ä¿‚ã‚’åˆ†æã—ãŸã‹
- [ ] ãƒ•ã‚¡ã‚¤ãƒ«ç«¶åˆã®å¯èƒ½æ€§ã‚’æ¤œè¨¼ã—ãŸã‹
- [ ] å“è³ªåŸºæº–ã‚’æ˜ç¢ºã«ã—ãŸã‹

### å®Ÿè¡Œä¸­ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

- [ ] å„worktreeãŒæ­£å¸¸ã«ä½œæˆã•ã‚ŒãŸã‹
- [ ] Claude CLIãŒå„worktreeã§å®Ÿè¡Œã•ã‚Œã¦ã„ã‚‹ã‹
- [ ] ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨çŠ¶æ³ã‚’ç›£è¦–ã—ã¦ã„ã‚‹ã‹
- [ ] ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ã„ã‚‹ã‹
- [ ] é€²æ—ã‚’å®šæœŸçš„ã«ç¢ºèªã—ã¦ã„ã‚‹ã‹

### å®Ÿè¡Œå¾Œãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

- [ ] å…¨ã‚¿ã‚¹ã‚¯ãŒå®Œäº†ã—ãŸã‹
- [ ] å“è³ªãƒã‚§ãƒƒã‚¯ã‚’å®Ÿæ–½ã—ãŸã‹
- [ ] ãƒ†ã‚¹ãƒˆãŒå…¨ã¦æˆåŠŸã—ãŸã‹
- [ ] ã‚«ãƒãƒ¬ãƒƒã‚¸åŸºæº–ã‚’æº€ãŸã—ãŸã‹
- [ ] ã‚³ãƒ¼ãƒ‰å“è³ªåŸºæº–ã‚’æº€ãŸã—ãŸã‹
- [ ] é©åˆ‡ã«ãƒãƒ¼ã‚¸ã§ããŸã‹
- [ ] worktreeã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã—ãŸã‹
- [ ] ãƒ­ã‚°ã‚’ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã—ãŸã‹

## ğŸ“š å‚è€ƒè³‡æ–™

- [Git Worktreeå…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://git-scm.com/docs/git-worktree)
- [ä¸¦åˆ—é–‹ç™ºå®Ÿè¨¼å ±å‘Šæ›¸](../../memory-bank/08-automation/git_worktree_parallel_development.md)
- [ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå“è³ªåŸºæº–](../../CLAUDE.md)
- [TDDå®Ÿè£…ãƒ‘ã‚¿ãƒ¼ãƒ³](../../memory-bank/03-patterns/generic_tdd_patterns.md)

---

**æ–‡æ›¸ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: 1.0.0  
**æœ€çµ‚æ›´æ–°**: 2025-06-07  
**æ¬¡å›ãƒ¬ãƒ“ãƒ¥ãƒ¼äºˆå®š**: 2025-07-07