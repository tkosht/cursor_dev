"""
Gemini A2A Agent

Google Gemini 2.5 Pro ã‚’ä½¿ç”¨ã—ãŸA2Aã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
"""

import logging
from typing import Any, Dict, List

from a2a.types import AgentSkill

from ..utils.config import AgentConfig
from ..utils.gemini_client import GeminiAPIError, GeminiClient
from ..utils.gemini_config import GeminiConfig
from .base_agent import BaseA2AAgent

logger = logging.getLogger(__name__)


class GeminiA2AAgent(BaseA2AAgent):
    """Gemini 2.5 Pro ã‚’ä½¿ç”¨ã—ãŸA2Aã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"""

    # ã‚¯ãƒ©ã‚¹å®šæ•°
    MAX_CONTEXT_MESSAGES = 20  # ä¼šè©±å±¥æ­´ã®æœ€å¤§ä¿æŒæ•°ï¼ˆ10å¾€å¾©åˆ†ï¼‰
    MAX_INPUT_LENGTH = 10000  # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã®æœ€å¤§é•·

    def __init__(
        self, config: AgentConfig, gemini_config: GeminiConfig
    ) -> None:
        """
        Args:
            config: A2Aã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­å®š
            gemini_config: Gemini APIè¨­å®š
        """
        super().__init__(config)
        self.gemini_config = gemini_config
        self.gemini_client = GeminiClient(gemini_config)
        self.conversation_context: List[str] = []

        # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå›ºæœ‰ã®ãƒ­ã‚°è¨­å®š
        self.logger = logging.getLogger(f"{__name__}.{config.name}")
        self.logger.info(
            f"Gemini agent initialized with model: {gemini_config.model}"
        )

    def get_skills(self) -> List[AgentSkill]:
        """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã‚¹ã‚­ãƒ«ä¸€è¦§ã‚’å–å¾—"""
        return [
            AgentSkill(
                id="chat",
                name="intelligent_chat",
                description="Have an intelligent conversation using Gemini 2.5 Pro",
                tags=["conversation", "ai", "general"],
            ),
            AgentSkill(
                id="qa",
                name="question_answering",
                description="Answer questions using advanced AI capabilities",
                tags=["qa", "knowledge", "research"],
            ),
            AgentSkill(
                id="help",
                name="help_assistant",
                description="Provide help and guidance",
                tags=["help", "assistance", "guide"],
            ),
        ]

    def _handle_gemini_api_error(self, error: GeminiAPIError) -> str:
        """
        GeminiAPIErrorã‚’åˆ†é¡ã—ã¦é©åˆ‡ãªãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿”ã™

        Args:
            error: GeminiAPIErrorä¾‹å¤–

        Returns:
            ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ãªã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        """
        error_msg = str(error)

        if "SAFETY_FILTER" in error_msg:
            self.logger.warning(
                "ğŸš¨ Safety filter activated - adjusting response"
            )
            return (
                "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ãŒã€å®‰å…¨æ€§ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã«ã‚ˆã‚Š"
                "ã“ã®å†…å®¹ã«ã¤ã„ã¦ãŠç­”ãˆã§ãã¾ã›ã‚“ã€‚"
                "åˆ¥ã®è³ªå•ã‚’ãŠè©¦ã—ãã ã•ã„ã€‚"
            )
        elif "RECITATION_FILTER" in error_msg:
            self.logger.warning("ğŸš¨ Recitation filter activated")
            return (
                "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ãŒã€è‘—ä½œæ¨©ã®è¦³ç‚¹ã‹ã‚‰"
                "ã“ã®å†…å®¹ã«ã¤ã„ã¦ãŠç­”ãˆã§ãã¾ã›ã‚“ã€‚"
            )
        elif "CONTENT_FILTER" in error_msg:
            self.logger.warning("ğŸš¨ Content filter activated")
            return (
                "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ãŒã€å†…å®¹ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã«ã‚ˆã‚Š"
                "ã“ã®è³ªå•ã«ã¯ãŠç­”ãˆã§ãã¾ã›ã‚“ã€‚"
            )
        elif "APIã‚­ãƒ¼ãŒæœŸé™åˆ‡ã‚Œ" in error_msg:
            self.logger.error("ğŸš¨ API key expired")
            return (
                "ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼: APIã‚­ãƒ¼ãŒæœŸé™åˆ‡ã‚Œã§ã™ã€‚"
                "ç®¡ç†è€…ã«ãŠå•ã„åˆã‚ã›ãã ã•ã„ã€‚"
            )
        elif "ä½¿ç”¨åˆ¶é™" in error_msg:
            self.logger.warning("ğŸš¨ API quota exceeded")
            return (
                "ä¸€æ™‚çš„ã«ã‚µãƒ¼ãƒ“ã‚¹ãŒæ··é›‘ã—ã¦ã„ã¾ã™ã€‚"
                "ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚"
            )
        else:
            # ãã®ä»–ã®APIã‚¨ãƒ©ãƒ¼
            self.logger.error(f"ğŸš¨ Unclassified API error: {error_msg}")
            return (
                "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚AIã‚µãƒ¼ãƒ“ã‚¹ã«ä¸€æ™‚çš„ãªå•é¡ŒãŒç™ºç”Ÿã—ã¦ã„ã¾ã™ã€‚"
                "ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚"
            )

    async def process_user_input(self, user_input: str) -> str:
        """
        ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚’Gemini 2.5 Proã§å‡¦ç†

        Args:
            user_input: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ

        Returns:
            GeminiãŒç”Ÿæˆã—ãŸå¿œç­”ãƒ†ã‚­ã‚¹ãƒˆ
        """
        try:
            # å…¥åŠ›ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
            sanitized_input = self._sanitize_user_input(user_input)

            # ç‰¹åˆ¥ãªã‚³ãƒãƒ³ãƒ‰ã®å‡¦ç†
            if self._is_help_command(sanitized_input):
                return self._get_help_message()

            elif self._is_clear_command(sanitized_input):
                return self._clear_conversation_context()

            elif self._is_status_command(sanitized_input):
                return await self._get_status_message()

            # é€šå¸¸ã®å¯¾è©±å‡¦ç†
            prompt = self._build_conversation_prompt(sanitized_input)
            self.logger.debug(f"æœ€çµ‚çš„ã«APIã«é€ä¿¡ã•ã‚Œã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {prompt}")
            response = await self.gemini_client.generate_response_with_timeout(
                prompt, timeout=15.0  # 5ç§’â†’15ç§’ã«å»¶é•·
            )

            # ä¼šè©±å±¥æ­´ã‚’æ›´æ–°
            self._update_conversation_context(sanitized_input, response)

            return response

        except ValueError as e:
            self.logger.warning(f"Input validation error: {e}")
            return f"å…¥åŠ›ã‚¨ãƒ©ãƒ¼: {e}"

        except GeminiAPIError as e:
            self.logger.error(f"Gemini API error: {e}")
            return self._handle_gemini_api_error(e)

        except Exception as e:
            self.logger.error(f"Unexpected error in process_user_input: {e}")
            return (
                "äºˆæœŸã—ãªã„å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"
                "ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚"
            )

    def _sanitize_user_input(self, user_input: str) -> str:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã®ã‚µãƒ‹ã‚¿ã‚¤ã‚º"""
        if not user_input:
            raise ValueError("å…¥åŠ›ãŒç©ºã§ã™")

        sanitized = user_input.strip()

        if len(sanitized) > self.MAX_INPUT_LENGTH:
            raise ValueError(
                f"å…¥åŠ›ãŒé•·ã™ãã¾ã™ï¼ˆæœ€å¤§{self.MAX_INPUT_LENGTH}æ–‡å­—ï¼‰"
            )

        return sanitized

    def _is_help_command(self, input_text: str) -> bool:
        """ãƒ˜ãƒ«ãƒ—ã‚³ãƒãƒ³ãƒ‰ã‹ã©ã†ã‹åˆ¤å®š"""
        return input_text.lower() in ["help", "?", "ãƒ˜ãƒ«ãƒ—"]

    def _is_clear_command(self, input_text: str) -> bool:
        """ã‚¯ãƒªã‚¢ã‚³ãƒãƒ³ãƒ‰ã‹ã©ã†ã‹åˆ¤å®š"""
        return input_text.lower() in ["clear", "ã‚¯ãƒªã‚¢", "ãƒªã‚»ãƒƒãƒˆ"]

    def _is_status_command(self, input_text: str) -> bool:
        """ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒãƒ³ãƒ‰ã‹ã©ã†ã‹åˆ¤å®š"""
        return input_text.lower() in ["status", "ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", "çŠ¶æ…‹"]

    def _build_conversation_prompt(self, user_input: str) -> str:
        """ä¼šè©±å±¥æ­´ã‚’è€ƒæ…®ã—ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰"""
        # base_prompt = ""  # â˜…ä¸€æ™‚çš„ã«ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç©ºã«ã™ã‚‹ (èª¿æŸ»ã®ãŸã‚)
        # # base_prompt = (
        # #     "ã‚ãªãŸã¯è¦ªåˆ‡ã§çŸ¥è­˜è±Šå¯ŒãªAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"
        # #     "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã—ã¦ã€æ­£ç¢ºã§æœ‰ç”¨ãªå›ç­”ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚"
        # #     "å›ç­”ã¯åˆ†ã‹ã‚Šã‚„ã™ãã€é©åº¦ãªé•·ã•ã§è¡Œã£ã¦ãã ã•ã„ã€‚\n\n"
        # # )

        # # ä¼šè©±å±¥æ­´ãŒã‚ã‚Œã°è¿½åŠ ï¼ˆæœ€æ–°6ä»¶=3å¾€å¾©åˆ†ï¼‰
        # if self.conversation_context:
        #     recent_context = self.conversation_context[-6:]
        #     conversation_history = "\n".join(recent_context)
        #     # base_prompt ãŒç©ºãªã®ã§ã€å±¥æ­´ãŒã‚ã‚‹å ´åˆã¯å±¥æ­´ã‹ã‚‰å§‹ã¾ã‚‹
        #     if base_prompt:  # base_promptãŒç©ºã§ãªã„å ´åˆã®ã¿æ”¹è¡Œã‚’è¿½åŠ 
        #         base_prompt += f"ä¼šè©±å±¥æ­´:\n{conversation_history}\n\n"
        #     else:
        #         base_prompt = f"ä¼šè©±å±¥æ­´:\n{conversation_history}\n\n"

        # base_prompt += f"ãƒ¦ãƒ¼ã‚¶ãƒ¼: {user_input}\nã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ: "

        # return base_prompt
        return user_input  # â˜…â˜…â˜… æœ€ã‚‚ã‚·ãƒ³ãƒ—ãƒ«ãªå½¢ (ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€å±¥æ­´ã€æ¥é ­è¾/æ¥å°¾è¾ãªã—)

    def _update_conversation_context(
        self, user_input: str, ai_response: str
    ) -> None:
        """ä¼šè©±å±¥æ­´ã‚’æ›´æ–°"""
        self.conversation_context.extend(
            [f"User: {user_input}", f"Assistant: {ai_response}"]
        )

        # ä¸Šé™ã‚’è¶…ãˆãŸå ´åˆã¯å¤ã„å±¥æ­´ã‚’å‰Šé™¤
        if len(self.conversation_context) > self.MAX_CONTEXT_MESSAGES:
            self.conversation_context = self.conversation_context[
                -self.MAX_CONTEXT_MESSAGES :
            ]

    def _clear_conversation_context(self) -> str:
        """ä¼šè©±å±¥æ­´ã‚’ã‚¯ãƒªã‚¢"""
        self.conversation_context.clear()
        return "âœ… ä¼šè©±å±¥æ­´ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸã€‚æ–°ã—ã„ä¼šè©±ã‚’å§‹ã‚ã¾ã—ã‚‡ã†ï¼"

    async def _get_status_message(self) -> str:
        """ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç”Ÿæˆ"""
        health = await self.gemini_client.health_check()
        client_info = self.gemini_client.get_client_info()

        return (
            f"ğŸ¤– {self.config.name}\n"
            f"ğŸ“¡ URL: {self.config.url}\n"
            f"ğŸ§  Model: {client_info['model']}\n"
            f"ğŸŒ¡ï¸ Temperature: {client_info['temperature']}\n"
            f"ğŸ“ Max Tokens: {client_info['max_tokens']}\n"
            f"ğŸ’š Status: {'âœ… OK' if health else 'âŒ ERROR'}\n"
            f"ğŸ’¬ Context: {len(self.conversation_context)} messages\n"
            f"ğŸ”‘ API Key: {client_info['api_key_masked']}"
        )

    def _get_help_message(self) -> str:
        """ãƒ˜ãƒ«ãƒ—ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç”Ÿæˆ"""
        return (
            f"ğŸ¤– **{self.config.name}** - Gemini 2.5 Proæ­è¼‰ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n\n"
            "ğŸ“ **ä½¿ã„æ–¹:**\n"
            "â€¢ è³ªå•ã‚„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è‡ªç”±ã«é€ä¿¡ã—ã¦ãã ã•ã„\n"
            "â€¢ `status` - ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®çŠ¶æ…‹ç¢ºèª\n"
            "â€¢ `clear` - ä¼šè©±å±¥æ­´ã‚’ã‚¯ãƒªã‚¢\n"
            "â€¢ `help` - ã“ã®ãƒ˜ãƒ«ãƒ—ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º\n\n"
            "ğŸ§  **ç‰¹å¾´:**\n"
            "â€¢ Google Gemini 2.5 Proã«ã‚ˆã‚‹é«˜åº¦ãªå¯¾è©±\n"
            "â€¢ ä¼šè©±å±¥æ­´ã‚’è€ƒæ…®ã—ãŸæ–‡è„ˆç†è§£\n"
            "â€¢ A2Aãƒ—ãƒ­ãƒˆã‚³ãƒ«å®Œå…¨æº–æ‹ \n"
            "â€¢ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¿œç­”\n\n"
            "ğŸ’¡ **æŠ€è¡“ä»•æ§˜:**\n"
            f"â€¢ Model: {self.gemini_config.model}\n"
            f"â€¢ Temperature: {self.gemini_config.temperature}\n"
            f"â€¢ Max Context: {self.MAX_CONTEXT_MESSAGES // 2} å¾€å¾©\n\n"
            "ä½•ã§ã‚‚ãŠæ°—è»½ã«ãŠèã‹ã›ãã ã•ã„ï¼âœ¨"
        )

    def get_agent_stats(self) -> Dict[str, Any]:
        """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®çµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
        return {
            "conversation_messages": len(self.conversation_context),
            "max_context_messages": self.MAX_CONTEXT_MESSAGES,
            "gemini_model": self.gemini_config.model,
            "gemini_temperature": self.gemini_config.temperature,
            "skills_count": len(self.get_skills()),
        }
